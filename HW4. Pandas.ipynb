{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV_DFHwgFLxt"
      },
      "source": [
        "# Advanced Programming and Data Analysis\n",
        "\n",
        "## HSE, 2024-25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdTH3pxXFLxw"
      },
      "source": [
        "### Home Work #4. Pandas Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk5URBvkFLxx"
      },
      "source": [
        "Assignment completed by:\n",
        "\n",
        "    (fill in your last name and first name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqVyveO4FLxx"
      },
      "source": [
        "### General information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A0wmBWwFLxx"
      },
      "source": [
        "__Publication date:__ 11.06.2025\n",
        "\n",
        "__Deadline:__ 04:00 19.06.2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK8Ari9eFLxz"
      },
      "source": [
        "### Grading and penalties\n",
        "\n",
        "Each task is assessed with 2 points.\n",
        "\n",
        "The grade for HA is calculated according to the following formula:\n",
        "\n",
        "$$\n",
        "s_{\\text{pandas}} \\times 1/2 ,\n",
        "$$\n",
        "\n",
        "where $s_{\\text{pandas}}$  ‚Äî¬†is the number of points you have scored in total on the tasks.\n",
        "\n",
        "\n",
        "Submitting a task late will incur a penalty of 1 point per day on the final grade for the task, but the delay cannot be more than 3 days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEGThfK6FLx0"
      },
      "source": [
        "__Attention!__ Homework assignments must be completed independently. \"Similar\" solutions are considered plagiarism, and all involved students (including those from whom the work was copied) will receive no more than 0 points for the assignment.\n",
        "\n",
        "Additionally, please remember that all solutions are run through a special new anti-plagiarism system for Jupyter notebooks, which detects cross-similarities between different notebooks, as well as solutions generated by neural networks. Such work will also be strictly considered as plagiarism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNja-u8vFLx0"
      },
      "source": [
        "### Submission format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H-cf8uaFLx0"
      },
      "source": [
        "You upload your solution using the link provided in the telegram channel. You need to upload a file with the extension .ipynb (Python notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46R1ipf0eUFY"
      },
      "source": [
        "### About the assignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPw-gfp5SPno"
      },
      "source": [
        "We've written the import code for you (no need to thank us, it was easy). From here on, you'll be writing the code yourself.\n",
        "\n",
        "[Here](https://habr.com/ru/companies/ruvds/articles/494720/) is a pandas cheat sheet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "568eb2d31004b87d22e119112ae01a1e75105f1d",
        "id": "8Pu4VL3gSPno"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW90LUAPSPnp"
      },
      "source": [
        "#### Data Description\n",
        "\n",
        "1. **Account ID**\n",
        "\n",
        "* **Description:** A unique identifier for each social media account in the dataset.\n",
        "* **Type:** Integer\n",
        "* **Example:** 1, 2, 3, ‚Ä¶\n",
        "\n",
        "2. **Username**\n",
        "\n",
        "* **Description:** The username or handle of the social media account.\n",
        "* **Type:** String\n",
        "* **Example:** john\\_doe, tech\\_guru\\_22, fitness\\_freak\n",
        "\n",
        "3. **Platform**\n",
        "\n",
        "* **Description:** The social media platform the account is using (Instagram, Twitter, Facebook, TikTok, LinkedIn).\n",
        "* **Type:** Categorical (String)\n",
        "* **Example:** Instagram, Twitter, Facebook, TikTok, LinkedIn\n",
        "\n",
        "4. **Follower Count**\n",
        "\n",
        "* **Description:** The total number of followers the account has.\n",
        "* **Type:** Integer\n",
        "* **Example:** 1500, 245000, 78000\n",
        "\n",
        "5. **Posts Per Week**\n",
        "\n",
        "* **Description:** The average number of posts the account creates per week.\n",
        "* **Type:** Integer\n",
        "* **Example:** 3, 5, 7\n",
        "\n",
        "6. **Engagement Rate**\n",
        "\n",
        "* **Description:** The percentage of interactions (likes, comments, shares) relative to the follower count. This is a measure of how engaging the content is.\n",
        "* **Type:** Float\n",
        "* **Range:** 0.01 to 0.15\n",
        "* **Example:** 0.045 (4.5% engagement rate)\n",
        "\n",
        "7. **Ad Spend (USD)**\n",
        "\n",
        "* **Description:** The monthly amount spent on advertising or promoting posts.\n",
        "* **Type:** Float\n",
        "* **Example:** 150.75, 850.00, 300.50\n",
        "\n",
        "8. **Conversion Rate**\n",
        "\n",
        "* **Description:** The percentage of users who take a desired action (e.g., clicking a link, signing up, etc.) after interacting with an ad.\n",
        "* **Type:** Float\n",
        "* **Range:** 0.01 to 0.05 (1% to 5% conversion rate)\n",
        "* **Example:** 0.025 (2.5% conversion rate)\n",
        "\n",
        "9. **Campaign Reach**\n",
        "\n",
        "* **Description:** The total number of unique users reached by the user‚Äôs campaigns in a given month.\n",
        "* **Type:** Integer\n",
        "* **Example:** 5000, 20000, 15000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pUyk4PySPnp"
      },
      "source": [
        "#### Task 0\n",
        "\n",
        "Load the data.\n",
        "Yes, yes ‚Äî **you won‚Äôt get any points for just reading a table** üòÑ\n",
        "\n",
        "\n",
        "**Hint**: [pd.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAv1RImbSPnp"
      },
      "outputs": [],
      "source": [
        "df = ... # ^‚®Ä·¥•‚®Ä^"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA3ddh5XSPnp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pllfZI3DSPnq"
      },
      "source": [
        "#### Task 1\n",
        "\n",
        "The column `Platform` contains the names of different platforms. Let‚Äôs imagine there is some order among them. Encode each platform as an integer (from 0 to N) and store this \"code\" in a new column called `Platform_Code`. Now calculate the **Spearman correlation** between all pairs of columns in the dataset (the result will be a correlation table).\n",
        "\n",
        "As your answer, output the value of the correlation between `Platform_Code` and `Engagement Rate`.\n",
        "You can briefly explain what the number means after printing it (no, this won‚Äôt be graded).\n",
        "\n",
        "\n",
        "**Hint**: [pd.factorize](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.factorize.html), [pd.DataFrame.select_dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html), [pd.DataFrame.corr](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSYo5E8-SPnq"
      },
      "outputs": [],
      "source": [
        "# ( ‡©≠ ÔΩ•·¥óÔΩ• )‡©≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuVBzzjwSPnq"
      },
      "source": [
        "#### Task 2\n",
        "\n",
        "Now take a look at the `Follower Count` column. It contains some numbers. Sometimes it‚Äôs useful to discretize such a feature. Split all values in the column into **4 groups**: `\"Low\"`, `\"Medium\"`, `\"High\"`, `\"Very High\"`. Each group should contain **25% of the data**. That is, \"Low\" contains the 25% of samples with the lowest values of the feature, and so on.\n",
        "\n",
        "Put the values `\"Low\"`, `\"Medium\"`, `\"High\"` or `\"Very High\"` for each sample into a new column called `Follower_Bin`.\n",
        "\n",
        "Now calculate the **average `Engagement Rate`** for each category in `Follower_Bin`.\n",
        "As your answer, output the value for the **\"High\"** category.\n",
        "\n",
        "\n",
        "**Hint**: [pd.qcut](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html), [pd.groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html), [pd.DataFrame.mean](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyFXNz__SPnq"
      },
      "outputs": [],
      "source": [
        "# (‚óï^^‚óï)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo33Gdx8SPnq"
      },
      "source": [
        "#### Task 3\n",
        "\n",
        "Sometimes it‚Äôs useful to transform a wide table into a long one (for example, to visualize multiple features in a single chart). Yes, it might sound strange, but that‚Äôs exactly what you‚Äôll do now.\n",
        "\n",
        "Create a new DataFrame `melted_df`, in which **each sample from the dataset appears 6 times**: once for each of the following values: `'Follower Count'`, `'Posts Per Week'`, `'Ad Spend (USD)'`, `'Conversion Rate'`, `'Engagement Rate'`, and `'Campaign Reach'`.\n",
        "\n",
        "In other words, you take a single row from the original dataset and turn it into 6 separate rows.\n",
        "Each of these rows should have a column `Metric` that contains the name of one of the 6 features listed above, and a column `Value` that contains the corresponding value from the sample. The `Platform` value should be **repeated** across all 6 rows.\n",
        "\n",
        "In other words,\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"Account ID\": 1,\n",
        "    \"Username\": \"harrislisa\",\n",
        "    \"Platform\": \"TikTok\",\n",
        "    \"Follower Count\": 54217,\n",
        "    \"Posts Per Week\": 3,\n",
        "    \"Engagement Rate\": 0.0986,\n",
        "    \"Ad Spend (USD)\": 538.1,\n",
        "    \"Conversion Rate\": 0.049,\n",
        "    \"Campaign Reach\": 1308,\n",
        "    \"Platform_Code\": 0,\n",
        "    \"Follower_Bin\": \"Low\"\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "is transformed into\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"Platform\": \"TikTok\",\n",
        "    \"Metric\": \"Follower Count\",\n",
        "    \"Value\": 54217,\n",
        "},\n",
        "{\n",
        "    \"Platform\": \"TikTok\",\n",
        "    \"Metric\": \"Posts Per Week\",\n",
        "    \"Value\": 3,\n",
        "}, ...\n",
        "```\n",
        "\n",
        "For each unique (`Platform`, `Metric`) pair, calculate the mode of the `Value` column. If multiple modes exist, keep only the largest one. Then, sum all of these selected mode values. In other words, you need to output the total sum of the largest mode values for all unique (`Platform`, `Metric`) pairs.\n",
        "\n",
        "\n",
        "**Hint**: [pd.melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html), [pd.DataFrame.mode](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mode.html), [pd.DataFrameGroupBy.agg](https://pandas.pydata.org/docs/dev/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbwh0_q6SPnq"
      },
      "outputs": [],
      "source": [
        "# („Å•‡πë‚Ä¢·¥ó‚Ä¢‡πë)„Å•‚ô°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNINIfVoSPnq"
      },
      "source": [
        "#### Task 4\n",
        "\n",
        "Now we want to look at the most popular accounts on different platforms. For each platform, sort the DataFrame in descending order by `Follower Count` ‚Äî do this without using loops, by sorting the entire DataFrame at once. Then, keep only the top 3 rows for each platform ‚Äî these will represent the three most popular accounts on each platform. As your answer, output the resulting table and the minimum `Follower Count` value in that table. Hint: you can apply functions to a `groupby` object ‚Äî this is equivalent to applying a function to each group within the grouped object. Read more about applying `apply` to a DataFrame after `groupby` [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#flexible-apply).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lhekxmMSPnq"
      },
      "outputs": [],
      "source": [
        "# Œµ(¬¥Ô≠ÅÔ∏µÔ≠Å`)–∑"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMiYVtGRSPnr"
      },
      "source": [
        "#### Task 5\n",
        "\n",
        "We want to calculate a certain metric to analyze the influence of accounts with different conversion rates. Specifically, we‚Äôre interested in the ratio of the difference in total follower count between high and low conversion groups to the total campaign reach across those groups for each platform. This will help us understand how much more influential high-conversion accounts are compared to low-conversion ones.\n",
        "\n",
        "Let‚Äôs define the *Conversion Influence* metric as follows:\n",
        "\n",
        "$Conversion¬†Influence = \\frac{Total¬†Follower\\ Count¬†(High) - Total¬†Follower\\ Count¬†(Low)}{Total¬†Campaign¬†Reach¬†(High)+Total¬†Campaign¬†Reach¬†(Low)}$\n",
        "\n",
        "We will calculate this metric **for each `Platform`**. In this formula, ‚ÄúHigh‚Äù refers to samples where `Conversion Rate` is greater than the median value, and ‚ÄúLow‚Äù refers to samples where `Conversion Rate` is less than or equal to the median. `Total Feature` refers to the sum of the given feature (`Follower Count` or `Campaign Reach`) within the corresponding group.\n",
        "\n",
        "To avoid recalculating which samples are ‚ÄúHigh‚Äù or ‚ÄúLow‚Äù repeatedly, create a new column in your dataset called `Conversion_Category`, which should contain either `\"High\"` or `\"Low\"` for each row based on the median split.\n",
        "\n",
        "Then, build a pivot table using `pd.pivot_table` that summarizes the total values of `Follower Count` and `Campaign Reach` for each combination of `Platform` and `Conversion_Category`. Use this table to compute the `Conversion Influence` metric for each platform.\n",
        "\n",
        "As your answer, output the **platform with the highest `Conversion Influence`**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0rdy0xASPnr"
      },
      "outputs": [],
      "source": [
        "# (Ô∏∂œâÔ∏∂)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa0zwfw7SPnr"
      },
      "source": [
        "#### Task 6\n",
        "\n",
        "We know you enjoyed calculating metrics using formulas, so let‚Äôs reinforce that success. This time, for each platform, we‚Äôll evaluate how effective advertising is based on **rolling groups of three consecutive records** from the dataset.\n",
        "\n",
        "Start by sorting the records **within each platform** in descending order of `Posts Per Week`. The idea is that accounts posting more frequently are likely using more \"active\" advertising strategies.\n",
        "\n",
        "Next, calculate **rolling sums with a window of 3** for both `Campaign Reach` and `Ad Spend (USD)`. A rolling sum with window size 3 means you move through the data, taking every group of three consecutive rows and summing the values in the target column. For the first two rows, there won't be enough preceding records to form a window, so the rolling values will be `NaN` ‚Äî that‚Äôs okay and can be ignored in further steps.\n",
        "\n",
        "Now, for each rolling window, compute the following metric:\n",
        "\n",
        "$Rolling¬†Efficiency¬†Ratio = \\frac{Rolling\\ Sum\\ of\\ Campaign\\ Reach}{Rolling\\ Sum\\ of\\ Ad\\ Spend}$\n",
        "\n",
        "This tells you, for each window, how many users were reached per one dollar spent on ads.\n",
        "\n",
        "From the rolling values computed for each platform, determine the **maximum Rolling Efficiency Ratio**. Then, identify:\n",
        "\n",
        "* The platform with the **highest maximum** efficiency\n",
        "* The platform with the **lowest maximum** efficiency\n",
        "\n",
        "Output **exactly two** platform names ‚Äî one with the **highest** and one with the **lowest** maximum rolling efficiency.\n",
        "\n",
        "**Hint**: You can use [`pd.DataFrame.rolling`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html) to compute rolling window sums.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqocx31VSPnr"
      },
      "outputs": [],
      "source": [
        "# (‚óî/‚Äø\\‚óî)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PCKqVUqSPnr"
      },
      "source": [
        "#### Task 7\n",
        "\n",
        "We‚Äôre not done showing you the beauty of pandas just yet. Now you‚Äôll calculate how many accounts on each platform are simultaneously the best in both `Engagement Rate` and `Conversion Rate`.\n",
        "\n",
        "Start by creating **two separate subsets** of the data:\n",
        "\n",
        "1. In the first subset, keep only the **top account** by `Engagement Rate` **for each platform**.\n",
        "2. In the second subset, keep only the **top account** by `Conversion Rate` **for each platform**.\n",
        "\n",
        "Then, **merge** these two subsets by the `Platform` column so that each row contains the platform name along with both top accounts ‚Äî one for engagement, one for conversion.\n",
        "\n",
        "Now, check whether the **account names (usernames)** in each merged row are the same.\n",
        "As your answer, output the **number of rows where the usernames match**, i.e., how many accounts are simultaneously top-ranked by both metrics on the same platform.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKZKJCFCSPnr"
      },
      "outputs": [],
      "source": [
        "# ( Õ°¬∞ Õú ñ Õ°¬∞)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-LItHABSPnr"
      },
      "source": [
        "#### Task 8\n",
        "\n",
        "Let‚Äôs do something simpler now. For each platform, calculate the **ratio of the total number of followers** for accounts with **high conversion** to the total number of followers for accounts with **low conversion**. This will help us understand how much high-conversion accounts ‚Äúdominate‚Äù over low-conversion accounts in terms of follower count.\n",
        "\n",
        "Define **high conversion** as `Conversion Rate` greater than the **mean**, and everything else as **low conversion**.\n",
        "\n",
        "For each platform:\n",
        "\n",
        "* Calculate the **sum of `Follower Count`** for high-conversion accounts.\n",
        "* Calculate the **sum of `Follower Count`** for low-conversion accounts.\n",
        "* Compute the **ratio** of high to low.\n",
        "\n",
        "As your answer, output:\n",
        "\n",
        "1. The **difference** between the **largest** and **smallest** such ratio across all platforms.\n",
        "2. The **names of the platforms** corresponding to the largest and smallest ratios.\n",
        "\n",
        "Use the magic command `%%time` at the beginning of your script to measure how long your pandas script takes to execute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VwmpLiiSPnr"
      },
      "outputs": [],
      "source": [
        "# (‚ó°‚Äø‚ó°‚úø)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD8jpeyOSPnr"
      },
      "source": [
        "#### Task 9\n",
        "\n",
        "Now solve Task 8 using **pure Python** ‚Äî that is, without using any pandas functions or methods. Only basic Python tools like loops, dictionaries, and conditionals. Measure how long your code takes to execute.\n",
        "\n",
        "To iterate over the DataFrame, you can convert it into a generator using [`df.iterrows()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html) or [`df.itertuples()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples). These aren‚Äôt the only ways to iterate over a DataFrame, but they‚Äôll help here.\n",
        "\n",
        "At the end, **compare the execution time** of your pure Python solution with the pandas solution from Task 8.\n",
        "Finally, state clearly **who won**: pure Python or pandas?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHz6dld3SPnr"
      },
      "outputs": [],
      "source": [
        "# (‚úø‚ó†‚Äø‚ó†)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcVXGYJ2SPnr"
      },
      "source": [
        "**And the winner is**: \\<MY ANSWER GOES HERE, I NOTICED THAT THE TASK REQUIRES WRITING SOMETHING AFTER THE CODE, OTHERWISE I WON‚ÄôT GET FULL POINTS FOR THE TASK>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRnSmAdXSPnr"
      },
      "source": [
        "#### Task 10\n",
        "\n",
        "A very serious task. Treat it accordingly. In the cell below, write your favorite joke or meme (just please, no overused ones, okay?). Bad jokes are allowed. Remember, this is a full-point task. The assistant checking your work **must smile**.\n",
        "\n",
        "If you're inserting an image, make sure **you don‚Äôt load it locally**. It would be unfortunate to lose points here just because you didn‚Äôt upload the image to the cloud and use a shareable link. And no, just pasting a URL isn‚Äôt enough ‚Äî either figure out how to embed the image properly, or go with a funny joke.\n",
        "\n",
        "There are only two chairs ‚Äî choose wisely...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAIml-kTSPnr"
      },
      "outputs": [],
      "source": [
        "# ‚Äø( ÃÅ Ãµ _-`)‚Äø"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}