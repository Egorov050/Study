
Начнем с того , что существует множество типов архитектур , но здесь мы рассмотрим микросервисную архитектуру. В чем разница , здесь [[Типы архитектур]]

js позволяет делать асинхронные запросы ( AJAX - Asynchronous JavaScript and XML). C помощью асинхронных запросов можно избежать полной перезагрузки HTML-страницы при каждом обращении к серверу. Вместо этого JavaScript может загружать только нужные данные или обновлённые элементы и динамически изменять часть контента на странице. Когда мы отпроавляем асинхроный запрос , у нас браузер ждет ответа от сервера , но мы не обновляемся и просто ждем ответа от сервера. И возвращает нам сервер не HTML , а просто данные , которые мы запросили , например в формате JSON. 

**NGINX** и **Apache** — это веб-серверы, которые используются для обработки и доставки веб-контента (например, HTML-страниц, файлов, API-ответов) пользователям. NGINX часто используется как фронтенд-сервер для обработки первых запросов пользователя и для доставки статических файлов (HTML, CSS, JS, изображения), которые не требуют серверной обработки.

Логика такая , позльзователь вводит в браузере url -> http get запрос отправляется на сервер NGINX -> он отправляет статические файлы HTML , CSS , JS 

<h3>Сборщик</h3>
Также у нас появляется сборщик. Сборщик ( например, Webpack, rollup , vite ) не участвует напрямую в обработке HTTP GET-запросов, но он играет важную роль в процессе подготовки и оптимизации ресурсов, которые потом обслуживаются через сервер (например, NGINX). 

Роль сборщика в контексте HTTP GET-запросов :
1. `Подготовка файлов` : Когда разработчик пишет код (например, JavaScript, CSS, изображения), сборщик используется для обработки и подготовки этих файлов перед тем, как они будут отправлены на сервер. Сборщик:
	- Объединяет модули JavaScript.
	- Минифицирует и оптимизирует код.
	- Преобразует современные версии кода (например, ES6) в более старые для совместимости с браузерами.
	- Собирает статические файлы и может даже сжимать изображения.
Это происходит на этапе разработки, когда проект собирается для деплоя (например, с помощью команд типа npm run build).

2. `Деплой на сервер` : После того как сборщик завершил свою работу, он генерирует оптимизированные файлы `Бандлы`. `bundlez` — это оптимизированный файл или группа файлов, которые содержат код и ресурсы для веб-приложения, что помогает улучшить его производительность. Эти файлы затем копируются на сервер.

3. `Обслуживание через NGINX` : Когда пользователи отправляют GET-запросы на сервер (например, при переходе на страницу), сервер (в частности, NGINX) отвечает, отдавая статические файлы (например, HTML, JS, CSS, изображения). **В этот момент сборщик уже не участвует** — он только подготавливает файлы до того, как они будут развернуты на сервере.

`Сборщик`  работает только на этапе **сборки** и **оптимизации** файлов (например, во время разработки или при подготовке к продакшену).

Также сборщик с помощью `babel` он может подготовить все к старым версиям. `Babel` — это инструмент для `транспиляции`  (преобразования) современного JavaScript в более старые версии, которые поддерживаются всеми браузерами. Он позволяет разработчикам использовать новейшие возможности JavaScript (например, ES6, ES7 и более новые версии), даже если некоторые браузеры ещё не поддерживают эти функции.






<h2>Бекенд</h2>
Наше ядро (приложение) взаимодействует изначально взаимодействует с реляционными базами данных. Это базы данных, которые используют таблицы для хранения данных, а также поддерживают SQL (Structured Query Language) для работы с данными. Данные организованы в строки и столбцы, где каждая строка — это запись, а столбцы — это атрибуты. Поддерживают отношения между таблицами, такие как первичные и внешние ключи. Поддерживают транзакции, которые обеспечивают целостность данных. 

Затем у нас появляется потребность в нереляционных базах данных (NoSQL). Эти базы данных не используют таблицы и SQL, и подходят для хранения данных, которые не требуют строгой структуры или нормализации. Бывает несколько типов : 
- **Документные базы данных**: Хранят данные в виде документов (например, JSON или BSON). Это MongoDB например 
- **Ключ-значение**: Хранят данные в виде пар ключ-значение, где каждый ключ уникален. Например Redis, Riak, DynamoDB
- **Колонковые базы данных**: Хранят данные в виде столбцов вместо строк, что оптимизирует работу с большими объемами данных. Напримеры Apache

<h3>Кэш</h3>
Мы можем хранить кеш в `Memcached`  или `Redis`  (Remote Dictionary Server). 
-  `Memcached`  это программное обеспечение, реализующее сервис кэширования данных в оперативной памяти на основе хеш-таблицы. 
-  `Redis`  это высокопроизводительная система управления базами данных, которая хранит данные в оперативной памяти и поддерживает несколько структур данных. Redis работает как `key-value store`  (хранилище данных типа “ключ-значение”) и часто используется для кеширования, управления сессиями, очередей задач и других задач, где требуется очень быстрая обработка данных.

Здесь мы можем хранить сессии пользователей , JVT токены ( [[JWT токены]] ) и т.д Подробнее здесь ( [[КЭШ]] ) 


<h3>CI / CD PIPLINE</H3>
CI/CD (Continuous Integration / Continuous Deployment) — это автоматизация разработки и выпуска программного обеспечения, которая позволяет команде регулярно интегрировать изменения, проходить тестирование и развертывать обновления на сервере без ручного вмешательства.
 
Основные шаги CI / CD Pipeline :
1. `Контроль версий и код-ревью` . Разработчики интегрируют изменения в репозиторий, обычно с применением Git. Все изменения проходят проверку код-ревью, чтобы убедиться в их качестве и согласованности.

2. `Запуск CI-теста` . Автоматизированные тесты (юнит-тесты, интеграционные тесты) проверяют корректность нового кода. При успешном прохождении тестов изменения считаются стабильными.

3. `Создание артефактов и сборка образа Docker` . Код упаковывается в Docker-контейнер — стандартный, изолированный и предсказуемый среда, которая содержит всё необходимое для запуска приложения (зависимости, библиотеки и т. д.).

4. `Сканирование безопасности` . Код проверяется на уязвимости, чтобы исключить возможность инъекций, утечек данных и других рисков.

5. `Автоматическое развертывание (CD)` . Docker-образ автоматически разворачивается на сервере, в тестовой или продакшн-среде. При этом используется оркестрация контейнеров (например, Kubernetes), которая позволяет автоматически управлять контейнерами, масштабировать их и балансировать нагрузку.

6. `Мониторинг и уведомления` . Успешное развертывание сопровождается мониторингом производительности и проверкой стабильности. В случае ошибок и сбоев система уведомляет команду, что позволяет оперативно исправить проблемы.

<h3>Docker</h3>
`Docker`  — это платформа, которая позволяет создавать, запускать и управлять контейнерами. Контейнеры, в отличие от виртуальных машин, изолируют приложение вместе с его зависимостями (библиотеками, конфигурациями и т.д.), но используют одну операционную систему (чаще всего ядро хоста), что делает их легковесными и позволяет быстрее запускаться.

Основные компоненты Docker : 
1. `Образы (images)`  — шаблоны, которые содержат всё необходимое для запуска приложения (код, зависимости, системные библиотеки). Из образов создаются контейнеры. Docker образ описывает, как должно выглядеть окружение приложения, и его можно создать с помощью Dockerfile — текстового файла, в котором описаны инструкции для сборки образа.
2. `Контейнеры`  — запущенные экземпляры образов, в которых работает приложение. Контейнеры изолированы друг от друга и от системы, что позволяет запускать несколько контейнеров на одной машине без конфликтов.
3. `Docker Hub`  — облачный репозиторий, где хранятся образы. Вы можете скачивать образы из Docker Hub или загружать туда собственные, чтобы другие пользователи могли использовать их в своих проектах.
4. `Docker Engine`  — движок, который управляет контейнерами. Docker Engine обрабатывает команды пользователя (например, docker run для запуска контейнера) и взаимодействует с операционной системой, создавая и удаляя контейнеры по запросу.

Преимущества Docker
- `Изоляция` . Docker-контейнеры полностью изолируют приложение и его зависимости, что устраняет проблемы несовместимости.
- `Портативность` . Контейнеры можно запустить на любом сервере или компьютере, где установлен Docker, что значительно упрощает перенос приложений между средами (например, из разработки в продакшн).
- `Экономия ресурсов` . Контейнеры используют меньше ресурсов, чем виртуальные машины, так как разделяют одно ядро системы, что позволяет запускать больше контейнеров на одной машине.
- `Легкость масштабирования и обновления` . С Docker проще развертывать приложения на кластерах (например, с Kubernetes) и управлять версиями приложения.


Docker играет ключевую роль в CI/CD pipeline, так как позволяет стандартизировать и изолировать окружения, в которых запускаются приложения на этапах интеграции, тестирования и развертывания. Благодаря Docker, вся команда разработки может быть уверена, что приложение будет работать одинаково на любом этапе пайплайна, будь то на локальной машине разработчика, в тестовой среде или на продакшн-сервере.

<h4>Как Docker используется в CI/CD pipeline</h4>
1. `Изоляция и воспроизводимость` . Docker позволяет создать единый образ приложения, который можно воспроизводить на всех этапах CI/CD. Вместо разного ПО и библиотек на разных серверах, все окружение упаковано в Docker-образ. Это значит, что если приложение протестировано и работает в контейнере, оно будет работать и на сервере, что снижает риск ошибок и конфликтов.
2. `Автоматизация сборки и тестирования` . На этапе CI Docker помогает создать изолированную среду, в которой запускается сборка и тестирование приложения.
	- `Сборка` . Docker-образ создается на основе Dockerfile, где указаны все зависимости и команды для запуска приложения.
	-  `Тестирование` . Контейнеры используются для запуска автоматизированных тестов (юнит-тестов, интеграционных и функциональных тестов). Это позволяет тестировать приложение в том же окружении, где оно будет развернуто, исключая несовместимость окружений.
3. `Стандартизация развертывания` . На этапе CD (непрерывного развертывания), Docker-образ с приложением отправляется в Docker Registry (например, Docker Hub), откуда он автоматически загружается на сервера. Используя один и тот же образ на всех серверах, вы гарантируете идентичность версий и окружения в тестовой и рабочей средах.
4. `Масштабирование и оркестрация` . Docker-контейнеры легко интегрируются с оркестраторами контейнеров, такими как Kubernetes. Это позволяет CI/CD pipeline не только развертывать приложение, но и масштабировать его при увеличении нагрузки, управлять контейнерами и балансировать трафик.
5. `Безопасность и надежность` . Docker-контейнеры изолируют приложение от основной операционной системы, снижая риски безопасности. Кроме того, Docker поддерживает создание многоуровневых образов, что позволяет использовать обновленные и безопасные базовые образы, минимизируя уязвимости в приложении.


<h3>Пример CI/CD pipeline с Docker</h3>
1. `Сборка Docker-образа` . Пайплайн создает образ приложения на основе Dockerfile.
2. `Тестирование образа` . Контейнер с образом запускается для выполнения тестов. Если тесты не проходят, пайплайн останавливается.
3. `Развертывание образа` . Если тесты успешны, образ загружается в Docker Registry. После этого пайплайн автоматически разворачивает контейнер на сервере.
4. `Мониторинг и уведомления` . После развертывания приложение мониторится, чтобы отслеживать его производительность и корректность работы.

С помощью Docker и CI/CD pipeline команды разработки могут легко автоматизировать тестирование, сборку и развертывание приложений, делая процесс более надежным, предсказуемым и быстрым.

И если мы говорим про микросервисную архитектуру , то CI/CD pipeline появляется у каждого сервиса , что делает развертывание сервисов независимым друг от друга. Ну и логично если какой-то сервис упадет , то другие сервисы будут работать без проблем. То есть отказоустойчисвоть значительно повышается.  


<h3>API GATEAWAY</H3>
1. **Ввод URL-адреса**: Вы начинаете процесс, вводя URL-адрес в адресной строке браузера, например, https://example.com/api.

2. **Отправка запроса**: Браузер отправляет HTTP-запрос на указанный URL. Этот запрос идет через интернет и достигает API Gateway — шлюза, который будет обрабатывать все входящие запросы.

3. **API Gateway**: API Gateway принимает запрос и выполняет несколько важных функций:

• **Маршрутизация**: Определяет, какой микросервис должен обработать запрос, основываясь на URL и других данных.

• **Аутентификация и авторизация**: Проверяет, имеет ли пользователь соответствующие права для доступа к ресурсу. Если запрос не авторизован, шлюз отклоняет его.

• **Обработка ошибок**: Если какой-либо микросервис не доступен или происходит ошибка, шлюз может вернуть пользовательское сообщение об ошибке.

4. **Направление запроса в микросервисы**: После обработки запроса API Gateway перенаправляет его к нужному микросервису. В случае сложных запросов шлюз может направить их сразу в несколько микросервисов для выполнения разных операций.

5. **Балансировка нагрузки**: Если система имеет несколько экземпляров одного микросервиса, API Gateway выполняет балансировку нагрузки, чтобы равномерно распределить запросы между этими экземплярами.

6. **Обработка микросервисом**: Микросервис, получивший запрос, выполняет нужную операцию (например, запрос к базе данных, выполнение бизнес-логики) и возвращает результат API Gateway.

7. **Агрегация данных (если необходимо)**: Если запрос требует данных от нескольких микросервисов, API Gateway может агрегировать их в единую структуру данных, прежде чем передать ответ обратно пользователю.

8. **Ответ клиенту**: После выполнения всех операций, API Gateway отправляет конечный ответ обратно в браузер, который отображает его пользователю.

9. **Дополнительные функции (по необходимости)**: API Gateway может также выполнять дополнительные операции, такие как кэширование данных, мониторинг трафика, защита от атак, например, от DDoS-атак, или выполнение логирования для аудита запросов.

  

Таким образом, API Gateway действует как центральная точка для всех запросов, обеспечивая их правильную маршрутизацию, безопасность и эффективность работы системы.


Про API GATEAWAY можно прочитать здесь https://habr.com/ru/articles/557004/
