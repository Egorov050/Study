
Начнем с того , что существует множество типов архитектур , но здесь мы рассмотрим микросервисную архитектуру. В чем разница , здесь [[Типы архитектур]]

js позволяет делать асинхронные запросы ( AJAX - Asynchronous JavaScript and XML). C помощью асинхронных запросов можно избежать полной перезагрузки HTML-страницы при каждом обращении к серверу. Вместо этого JavaScript может загружать только нужные данные или обновлённые элементы и динамически изменять часть контента на странице. Когда мы отпроавляем асинхроный запрос , у нас браузер ждет ответа от сервера , но мы не обновляемся и просто ждем ответа от сервера. И возвращает нам сервер не HTML , а просто данные , которые мы запросили , например в формате JSON. 

`NGINX` и `Apache` — это веб-серверы, которые используются для обработки и доставки веб-контента (например, HTML-страниц, файлов, API-ответов) пользователям. NGINX часто используется как фронтенд-сервер для обработки первых запросов пользователя и для доставки статических файлов (HTML, CSS, JS, изображения), которые не требуют серверной обработки.

Логика такая , позльзователь вводит в браузере url -> http get запрос отправляется на сервер NGINX -> он отправляет статические файлы HTML , CSS , JS 

<h3>Сборщик</h3>
Также у нас появляется сборщик. Сборщик ( например, Webpack, rollup , vite ) не участвует напрямую в обработке HTTP GET-запросов, но он играет важную роль в процессе подготовки и оптимизации ресурсов, которые потом обслуживаются через сервер (например, NGINX). 

Роль сборщика в контексте HTTP GET-запросов :
1. `Подготовка файлов` : Когда разработчик пишет код (например, JavaScript, CSS, изображения), сборщик используется для обработки и подготовки этих файлов перед тем, как они будут отправлены на сервер. Сборщик:
	- Объединяет модули JavaScript.
	- Минифицирует и оптимизирует код.
	- Преобразует современные версии кода (например, ES6) в более старые для совместимости с браузерами.
	- Собирает статические файлы и может даже сжимать изображения.
Это происходит на этапе разработки, когда проект собирается для деплоя (например, с помощью команд типа npm run build).

2. `Деплой на сервер` : После того как сборщик завершил свою работу, он генерирует оптимизированные файлы `Бандлы`. `bundlez` — это оптимизированный файл или группа файлов, которые содержат код и ресурсы для веб-приложения, что помогает улучшить его производительность. Эти файлы затем копируются на сервер.

3. `Обслуживание через NGINX` : Когда пользователи отправляют GET-запросы на сервер (например, при переходе на страницу), сервер (в частности, NGINX) отвечает, отдавая статические файлы (например, HTML, JS, CSS, изображения). **В этот момент сборщик уже не участвует** — он только подготавливает файлы до того, как они будут развернуты на сервере.

`Сборщик`  работает только на этапе **сборки** и **оптимизации** файлов (например, во время разработки или при подготовке к продакшену).

Также сборщик с помощью `babel` он может подготовить все к старым версиям. `Babel` — это инструмент для `транспиляции`  (преобразования) современного JavaScript в более старые версии, которые поддерживаются всеми браузерами. Он позволяет разработчикам использовать новейшие возможности JavaScript (например, ES6, ES7 и более новые версии), даже если некоторые браузеры ещё не поддерживают эти функции.






<h2>Бекенд</h2>
Наше ядро (приложение) взаимодействует изначально взаимодействует с реляционными базами данных. Это базы данных, которые используют таблицы для хранения данных, а также поддерживают SQL (Structured Query Language) для работы с данными. Данные организованы в строки и столбцы, где каждая строка — это запись, а столбцы — это атрибуты. Поддерживают отношения между таблицами, такие как первичные и внешние ключи. Поддерживают транзакции, которые обеспечивают целостность данных. 

Затем у нас появляется потребность в нереляционных базах данных (NoSQL). Эти базы данных не используют таблицы и SQL, и подходят для хранения данных, которые не требуют строгой структуры или нормализации. Бывает несколько типов : 
- **Документные базы данных**: Хранят данные в виде документов (например, JSON или BSON). Это MongoDB например 
- **Ключ-значение**: Хранят данные в виде пар ключ-значение, где каждый ключ уникален. Например Redis, Riak, DynamoDB
- **Колонковые базы данных**: Хранят данные в виде столбцов вместо строк, что оптимизирует работу с большими объемами данных. Напримеры Apache


<h3>Кэш</h3>
Мы можем хранить кеш в `Memcached`  или `Redis`  (Remote Dictionary Server). 
-  `Memcached`  это программное обеспечение, реализующее сервис кэширования данных в оперативной памяти на основе хеш-таблицы. 
-  `Redis`  это высокопроизводительная система управления базами данных, которая хранит данные в оперативной памяти и поддерживает несколько структур данных. Redis работает как `key-value store`  (хранилище данных типа “ключ-значение”) и часто используется для кеширования, управления сессиями, очередей задач и других задач, где требуется очень быстрая обработка данных.

Здесь мы можем хранить сессии пользователей , JWT токены ( [[JWT токены]] ) и т.д Подробнее здесь ( [[КЭШ]] )  


<h3>CI / CD PIPLINE</H3>
CI/CD (Continuous Integration / Continuous Deployment) — это автоматизация разработки и выпуска программного обеспечения, которая позволяет команде регулярно интегрировать изменения, проходить тестирование и развертывать обновления на сервере без ручного вмешательства.
 
Основные шаги CI / CD Pipeline :
1. `Контроль версий и код-ревью` . Разработчики интегрируют изменения в репозиторий, обычно с применением Git. Все изменения проходят проверку код-ревью, чтобы убедиться в их качестве и согласованности.
2. `Запуск CI-теста` . Автоматизированные тесты (юнит-тесты, интеграционные тесты) проверяют корректность нового кода. При успешном прохождении тестов изменения считаются стабильными.
3. `Создание артефактов и сборка образа Docker` . Код упаковывается в Docker-контейнер — стандартный, изолированный и предсказуемый среда, которая содержит всё необходимое для запуска приложения (зависимости, библиотеки и т. д.).
4. `Сканирование безопасности` . Код проверяется на уязвимости, чтобы исключить возможность инъекций, утечек данных и других рисков.
5. `Автоматическое развертывание (CD)` . Docker-образ автоматически разворачивается на сервере, в тестовой или продакшн-среде. При этом используется оркестрация контейнеров (например, Kubernetes), которая позволяет автоматически управлять контейнерами, масштабировать их и балансировать нагрузку.
6. `Мониторинг и уведомления` . Успешное развертывание сопровождается мониторингом производительности и проверкой стабильности. В случае ошибок и сбоев система уведомляет команду, что позволяет оперативно исправить проблемы.


<h3>Docker</h3>
`Docker`  — это платформа, которая позволяет создавать, запускать и управлять контейнерами. Контейнеры, в отличие от виртуальных машин, изолируют приложение вместе с его зависимостями (библиотеками, конфигурациями и т.д.), но используют одну операционную систему (чаще всего ядро хоста), что делает их легковесными и позволяет быстрее запускаться.

Основные компоненты Docker : 
1. `Образы (images)`  — шаблоны, которые содержат всё необходимое для запуска приложения (код, зависимости, системные библиотеки). Из образов создаются контейнеры. Docker образ описывает, как должно выглядеть окружение приложения, и его можно создать с помощью Dockerfile — текстового файла, в котором описаны инструкции для сборки образа.
2. `Контейнеры`  — запущенные экземпляры образов, в которых работает приложение. Контейнеры изолированы друг от друга и от системы, что позволяет запускать несколько контейнеров на одной машине без конфликтов.
3. `Docker Hub`  — облачный репозиторий, где хранятся образы. Вы можете скачивать образы из Docker Hub или загружать туда собственные, чтобы другие пользователи могли использовать их в своих проектах.
4. `Docker Engine`  — движок, который управляет контейнерами. Docker Engine обрабатывает команды пользователя (например, docker run для запуска контейнера) и взаимодействует с операционной системой, создавая и удаляя контейнеры по запросу.

Преимущества Docker
- `Изоляция` . Docker-контейнеры полностью изолируют приложение и его зависимости, что устраняет проблемы несовместимости.
- `Портативность` . Контейнеры можно запустить на любом сервере или компьютере, где установлен Docker, что значительно упрощает перенос приложений между средами (например, из разработки в продакшн).
- `Экономия ресурсов` . Контейнеры используют меньше ресурсов, чем виртуальные машины, так как разделяют одно ядро системы, что позволяет запускать больше контейнеров на одной машине.
- `Легкость масштабирования и обновления` . С Docker проще развертывать приложения на кластерах (например, с Kubernetes) и управлять версиями приложения.


Docker играет ключевую роль в CI/CD pipeline, так как позволяет стандартизировать и изолировать окружения, в которых запускаются приложения на этапах интеграции, тестирования и развертывания. Благодаря Docker, вся команда разработки может быть уверена, что приложение будет работать одинаково на любом этапе пайплайна, будь то на локальной машине разработчика, в тестовой среде или на продакшн-сервере.


<h4>Как Docker используется в CI/CD pipeline</h4>
1. `Изоляция и воспроизводимость` . Docker позволяет создать единый образ приложения, который можно воспроизводить на всех этапах CI/CD. Вместо разного ПО и библиотек на разных серверах, все окружение упаковано в Docker-образ. Это значит, что если приложение протестировано и работает в контейнере, оно будет работать и на сервере, что снижает риск ошибок и конфликтов.
2. `Автоматизация сборки и тестирования` . На этапе CI Docker помогает создать изолированную среду, в которой запускается сборка и тестирование приложения.
	- `Сборка` . Docker-образ создается на основе Dockerfile, где указаны все зависимости и команды для запуска приложения.
	-  `Тестирование` . Контейнеры используются для запуска автоматизированных тестов (юнит-тестов, интеграционных и функциональных тестов). Это позволяет тестировать приложение в том же окружении, где оно будет развернуто, исключая несовместимость окружений.
3. `Стандартизация развертывания` . На этапе CD (непрерывного развертывания), Docker-образ с приложением отправляется в Docker Registry (например, Docker Hub), откуда он автоматически загружается на сервера. Используя один и тот же образ на всех серверах, вы гарантируете идентичность версий и окружения в тестовой и рабочей средах.
4. `Масштабирование и оркестрация` . Docker-контейнеры легко интегрируются с оркестраторами контейнеров, такими как Kubernetes. Это позволяет CI/CD pipeline не только развертывать приложение, но и масштабировать его при увеличении нагрузки, управлять контейнерами и балансировать трафик.
5. `Безопасность и надежность` . Docker-контейнеры изолируют приложение от основной операционной системы, снижая риски безопасности. Кроме того, Docker поддерживает создание многоуровневых образов, что позволяет использовать обновленные и безопасные базовые образы, минимизируя уязвимости в приложении.


<h3>Пример CI/CD pipeline с Docker</h3>
1. `Сборка Docker-образа` . Пайплайн создает образ приложения на основе Dockerfile.
2. `Тестирование образа` . Контейнер с образом запускается для выполнения тестов. Если тесты не проходят, пайплайн останавливается.
3. `Развертывание образа` . Если тесты успешны, образ загружается в Docker Registry. После этого пайплайн автоматически разворачивает контейнер на сервере.
4. `Мониторинг и уведомления` . После развертывания приложение мониторится, чтобы отслеживать его производительность и корректность работы.

С помощью Docker и CI/CD pipeline команды разработки могут легко автоматизировать тестирование, сборку и развертывание приложений, делая процесс более надежным, предсказуемым и быстрым.

И если мы говорим про микросервисную архитектуру , то CI/CD pipeline появляется у каждого сервиса , что делает развертывание сервисов независимым друг от друга. Ну и логично если какой-то сервис упадет , то другие сервисы будут работать без проблем. То есть отказоустойчисвоть значительно повышается.  


<h3>API GATEAWAY</H3>
`API Gateway (шлюз API)`  — это сервер, который работает как единственная точка входа для всех внешних запросов в систему, обрабатывая и маршрутизируя их к соответствующим микросервисам. Он служит посредником между клиентами и микросервисами, выполняя следующие функции: маршрутизация запросов, агрегация данных, авторизация и аутентификация, балансировка нагрузки, кэширование, защита от атак и мониторинг. API Gateway позволяет уменьшить сложность клиентских приложений, централизовать управление и улучшить безопасность, а также оптимизировать взаимодействие с множеством сервисов.

Про API GATEAWAY можно прочитать здесь https://habr.com/ru/articles/557004/


<h3>Хранилища</h3>
s3 предоставляет облачное хранилище объектов, но не является полноценной базой данных. Оно идеально подходит для хранения больших объемов данных, таких как:
Статичные файлы: изображения, видео, лог-файлы, документы.
- `Архивы и резервные копии` : для долгосрочного хранения данных, которые редко изменяются.
- `Массовое хранение больших данных` : например, для аналитики или обработки больших объемов неструктурированных данных (например, для машинного обучения).
- `Контент для доставки` : с помощью `CDN (CloudFront)`  можно использовать S3 для доставки контента по всему миру.


<h3>ClickHouse</h3>
`ClickHouse`  — это система управления базами данных (СУБД), разработанная для хранения и обработки больших объемов данных в реальном времени. Она использует **колоночное хранилище** и ориентирована на аналитические запросы. Основная цель ClickHouse — это высокая производительность при обработке аналитических запросов на больших объемах данных. Используется для хранения логов. 


<h3>Брокер сообщений</h3>
`Брокер сообщений`  — это программное обеспечение, которое используется для обмена сообщениями между различными компонентами или сервисами в распределённых системах. Брокеры сообщений обеспечивают надёжную доставку сообщений и управление очередями, что позволяет различным системам и микросервисам взаимодействовать друг с другом, даже если они работают асинхронно и с различными темпами.

`RabbitMQ`  — это один из самых популярных брокеров сообщений, который реализует `AMQP (Advanced Message Queuing Protocol)` . Он широко используется для создания асинхронных, масштабируемых и отказоустойчивых систем.

Основные задачи и принципы работы брокера сообщений (например, RabbitMQ) :
1. `Асинхронная передача сообщений` : Брокер сообщений позволяет приложениям или сервисам обмениваться данными, не ожидая немедленного ответа. Это полезно для обработки запросов, которые могут занять продолжительное время, или когда одна система должна отправить данные другой системе для дальнейшей обработки. Например, в случае с `RabbitMQ`  сообщения отправляются в очередь, и потребители (или слушатели) могут извлечь их позже, когда будут готовы обработать.
2. `Декуплинг сервисов` : Брокер сообщений помогает изолировать сервисы друг от друга. Отправитель не зависит от получателя, а только от очереди сообщений. Это повышает гибкость и упрощает масштабирование системы. Например, если один сервис генерирует данные, а другой их обрабатывает, брокер сообщений позволяет этим сервисам работать независимо, не блокируя друг друга.
3. `Масштабируемость` : RabbitMQ помогает легко масштабировать систему, добавляя новые компоненты или узлы, которые могут обрабатывать сообщения в очереди. Это важно для больших распределенных систем с высокими требованиями к производительности. Системы могут быть горизонтально масштабированы, чтобы увеличивать пропускную способность, добавляя больше потребителей или серверов RabbitMQ.
4. `Управление нагрузкой` : Брокер сообщений помогает справиться с переменной нагрузкой. Когда нагрузка увеличивается, сообщения могут быть поставлены в очередь, и сервисы могут обрабатывать их по мере готовности, предотвращая перегрузку. Также это помогает в ситуациях, когда один компонент системы может быть временно недоступен — сообщения будут ждать в очереди, пока компонент не станет доступным.
5. `Гарантированная доставка сообщений` : RabbitMQ предоставляет механизмы для обеспечения надёжной доставки сообщений. Сообщения могут быть помечены как **persistent** (постоянные), что гарантирует их сохранность в случае сбоя сервера.Это критично для систем, где потеря данных может быть неприемлема (например, в банковских или финансовых приложениях).
6. `Обработка ошибок и повторная доставка сообщений` : RabbitMQ предоставляет возможности для обработки ошибок и повторной отправки сообщений в случае неудачной обработки (например, с использованием механизма “dead-letter” очередей). Это особенно полезно в микросервисной архитектуре, где один сервис может не успеть обработать сообщение и должен повторить попытку позже.
7. `Обмен сообщениями между различными языками и платформами` : RabbitMQ поддерживает множество языков программирования (например, Python, Java, .NET, Go, и другие), что позволяет интегрировать разные системы и платформы, независимо от их технологий.

`Что подразумевается под обменом сообщений?`  Пример обмена сообщениями можно рассмотреть на основе системы микросервисов, где один сервис генерирует событие, а другой его обрабатывает через брокер сообщений, например, RabbitMQ.

`Пример` : Обработка заказа в системе электронной коммерции
`Сценарий` : Пользователь делает заказ в интернет-магазине, и система должна выполнить несколько операций, таких как обработка оплаты, упаковка товара и отправка уведомлений. Вместо того чтобы все операции выполнялись синхронно, они могут быть обработаны асинхронно через обмен сообщениями.

`Шаги обмена сообщениями:`
1. `Пользователь делает заказ` : Когда пользователь оформляет заказ на сайте, система генерирует событие “Новый заказ”.
2. `Процесс отправки сообщения`  (Producer): Микросервис “Заказы” (Order Service) создает сообщение с данными о заказе (например, ID заказа, товары, данные пользователя и т.д.). Это сообщение помещается в очередь сообщений RabbitMQ.
3. `Хранение в очереди` : Брокер RabbitMQ принимает сообщение и помещает его в очередь “Новые заказы”.
4. `Обработка сообщения`  (Consumer): Сервис “Обработка заказов” (Order Processing Service) подписан на очередь “Новые заказы” и извлекает сообщение. Этот сервис начинает обработку заказа : проверка наличия товара на складе, подтверждение оплаты, упаковка и подготовка к отправке.
5. `Процесс отправки уведомлений` : После успешной обработки заказа сервис “Обработка заказов” может отправить новое сообщение в очередь “Уведомления” с данными для отправки уведомления пользователю. Сервис “Уведомления” (Notification Service) извлекает сообщение из очереди и отправляет пользователю email или SMS с подтверждением заказа.
6. `Заключительный этап` : Сервис “Уведомления” сообщает пользователю, что заказ успешно принят и будет отправлен.

Как работает обмен сообщениями в этом примере :
- `Асинхронность` : Сервисы работают независимо. Например, после того как заказ был получен, сервис “Обработка заказов” не ждет завершения всех этапов, он продолжает работу, а RabbitMQ берет на себя управление очередями и доставкой сообщений.
- `Масштабируемость` : Если количество заказов увеличится, можно добавить больше потребителей, чтобы ускорить обработку (например, больше сервисов для обработки заказов или отправки уведомлений).
- `Гарантированная доставка` : В случае сбоя сервисов или брокера сообщений, сообщения сохраняются и будут обработаны позже, когда сервисы снова станут доступными.

Плюсы обмена сообщениями в этом примере :
- `Изоляция` : Каждый сервис изолирован от других. Например, сервис “Заказы” не зависит от того, как быстро работает сервис “Уведомления”.
- `Обработка ошибок` : Если один из сервисов не может обработать сообщение, оно может быть отправлено в специальную очередь для ошибок, и будет повторно обработано позже.
- `Масштабируемость` : Когда нагрузка увеличится, можно просто добавить дополнительные экземпляры сервисов для обработки сообщений.



<h3>Scheduler</h3> 
Планировщик задач (Scheduler) в программировании — это инструмент или библиотека, которая позволяет автоматизировать выполнение задач или процессов в определённое время, по расписанию или в ответ на события. Он управляет временем выполнения задач, освобождая разработчиков от необходимости вручную запускать их, и помогает организовывать асинхронные процессы.

Вот несколько коротких сценариев использования : 
1. `Отправка email-уведомлений` : Планировщик задач запускает задачу отправки email-уведомлений пользователям каждый день в 9:00 утра, например, для напоминания о предстоящих событиях.
2. `Автоматическое резервное копирование` : Задача по созданию резервной копии базы данных запускается ежедневно в 2 часа ночи для минимизации нагрузки на сервер в рабочее время.
3. `Очистка временных файлов` : Каждые 30 минут планировщик запускает задачу для удаления временных файлов и кэшированных данных из директории приложения, чтобы освободить место на сервере.


