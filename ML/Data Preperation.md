Перед тем, как применять различные ml подели да и вообще работать с данными, нам нужно привести их в нормальное состояние. Рассмотрим несколько шагов.

<h2>Очистка данных</h2>
Удаление пропущенных значений:
-  *Удаление строк или столбцов* с пропущенными значениями.
- *Замена пропущенных значений* на средние, медианные или наиболее часто встречающиеся значения, или использование более сложных методов, таких как иммпутация. 
- *удаление дубликатов*

Делаем при помощи :
[]


<h2>Обработка категориальных данных (One hot encoding)</h2>
Для этого мы используем one hot encoding. Делается это вот таким способом : 

```python 
import pandas as pd

data = {
    'Марка машины': ['Toyota', 'Honda', 'BMW', 'Toyota', 'BMW', 'Honda'],
    'Год производства': [2010, 2012, 2010, 2018, 2012, 2018]
}
df = pd.DataFrame(data)


one_hot_encoded = pd.get_dummies(df, columns=['Марка машины', 'Год производства'])

one_hot_encoded = one_hot_encoded.astype(int)

print(one_hot_encoded)
```

Разберем этот код : 
Понятно, что мы создаем датафрейм и тд. 
По факту, мы используем функцию `pd.get_dummies` где уточняем наш датасет и колонки, которые нужно заинкодить:

```python
one_hot_encoded = pd.get_dummies(df, columns=['Марка машины', 'Год производства'])
```

Однако, после такого у нас будет вот такая таблица : 

```python 
Марка машины_BMW  Марка машины_Honda  Марка машины_Toyota  \
0             False               False                 True   
1             False                True                False   
2              True               False                False   
3             False               False                 True   
4              True               False                False   
5             False                True                False   

   Год производства_2010  Год производства_2012  Год производства_2018  
0                   True                  False                  False  
1                  False                   True                  False  
2                   True                  False                  False  
3                  False                  False                   True  
4                  False                   True                  False  
5                  False                  False                   True  
```

Так как нам нужны 0 и 1 , то мы прописываем обычную функцию, которая преобразует данные в цифры : 

```python 
one_hot_encoded = one_hot_encoded.astype(int)
```

Тогда мы получаем : 

```python
Марка машины_BMW  Марка машины_Honda  Марка машины_Toyota  \
0                 0                   0                    1   
1                 0                   1                    0   
2                 1                   0                    0   
3                 0                   0                    1   
4                 1                   0                    0   
5                 0                   1                    0   

   Год производства_2010  Год производства_2012  Год производства_2018  
0                      1                      0                      0  
1                      0                      1                      0  
2                      1                      0                      0  
3                      0                      0                      1  
4                      0                      1                      0  
5                      0                      0                      1
```

<h2>Масштабирование признаков</h2> 
Масштабирование признаков заключается в преобразовании данных таким образом, чтобы они имели схожие масштабы.

Масштабирование признаков необходимо для некоторых моделей машинного обучения, чтобы улучшить их производительность, численную стабильность и скорость сходимости. Ниже приведены категории моделей, которые требуют или не требуют масштабирования признаков.


<h3>Модели, которые нужно масштабировать признаки : </h3>
<h6>Методы на основе расстояния :</h6>
1) K-Nearest Neighbors (KNN) []: Использует евклидово расстояние для определения ближайших соседей. Несмасштабированные признаки могут значительно исказить результаты.
2) Кластеризация (например, K-Means): Расстояния между центроидами и точками данных зависят от масштаба признаков.
<h6>Линейные модели :</h6>
1) Логистическая регрессия и линейная регрессия: Масштабирование улучшает численную стабильность и скорость сходимости оптимизационных алгоритмов.


<h3>Модели, не требующие масштабирования</h3>
<h6>Деревья решений : </h6>
1) Decision Trees: Делают разбиения на основе порогов, поэтому масштаб данных не влияет на процесс разбиения.
2) Random Forest: Множество деревьев решений, не чувствительных к масштабу признаков.
3) Gradient Boosting: Так же как и деревья решений, не чувствителен к масштабу признаков.


<h2>Как мы это делаем?</h2>
```python 
# Инициализация 
StandardScaler scaler = StandardScaler() 
# Обучение scaler на тренировочных данных 
scaler.fit(X_train) 
# Преобразование тренировочных данных 
X_train_normed = scaler.transform(X_train) 
# Преобразование тестовых данных 
X_test_normed = scaler.transform(X_test)
```

*Мы должны это делать уже после того, как почистили датасет и поделили на тренировочный и тестовый семпл ! 

Применяем мы к следующим типам данных : 
Числовые (не категориальные) данные
    - Масштабирование применяется к числовым признакам, таким как возраст, зарплата, расстояние, количество и т.д.
    - Категориальные данные, которые были закодированы методом One-Hot Encoding, обычно не требуют масштабирования, так как они представлены в виде 0 и 1.
Признаки с различными диапазонами значений:
    - Если признаки имеют различные диапазоны значений, это может негативно повлиять на производительность модели. Например, если один признак варьируется от 1 до 10, а другой от 1000 до 10000, алгоритмы могут быть чувствительны к таким различиям.




*Примечание : Масштабирование числовых признаков после One-Hot Encoding не влияет на закодированные категориальные признаки. При масштабировании данные, полученные после one-hot encoding (столбцы с 0 и 1), останутся в неизменном виде, поскольку масштабирование не изменяет значения 0 и 1. Оно лишь приводит числовые признаки к заданному диапазону.*



