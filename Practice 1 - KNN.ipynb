{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFAuC7gVMVw-"
      },
      "source": [
        "# Advanced programming and data analysis\n",
        "\n",
        "## HSE University, 2024-25 Academic Year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1quje82JJevW"
      },
      "source": [
        "# Practice 1. Introduction to sklearn. KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye5PmjfGwt4y"
      },
      "source": [
        "### General workflow for solving a machine learning problem\n",
        "\n",
        "__Recall from the lecture:__\n",
        "* What is a machine learning task? What is given and what should be found?\n",
        "* What types of features are there in machine learning?\n",
        "* What types of tasks are there in machine learning?\n",
        "* What is a loss/quality function? What is it used for?\n",
        "\n",
        "Let us recall the general scheme for solving a machine learning problem:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/hse-ds/iad-intro-ds/blob/master/2023/seminars/sem05_sklearn_knn/static/scheme.png?raw=true\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "From the initial database, after preprocessing, we obtain a training sample $X, Y$.\n",
        "\n",
        "The object-attribute matrix $X$ has the size (number of objects) $\\times$ (number of features). One row of this matrix corresponds to one object of the training sample given as a vector of length (number of features). The features are numerical characteristics of the object. The vector of correct answers $Y$ has length (number of objects).\n",
        "\n",
        "At the training stage, an algorithm $a(x)$ is built (trained) on the basis of the training sample $X, Y$. It is a function that takes as an input the features of an object and returns a prediction for that object: $y \\approx a(x)$. Algorithm $a$ can make predictions for any valid objects; it can be applied to both learning objects and objects that the algorithm has never seen. This is the goal of machine learning: to identify patterns in the training sample that will allow one to make high-quality (fairly accurate) predictions on new objects $x$.\n",
        "\n",
        "How to train such algorithms $a(x)$ on a training sample is largely the focus of our course.\n",
        "\n",
        "\n",
        "### Scikit-learn Interface\n",
        "\n",
        "Scikit-Learn, or Sklearn for short, is a library that implements almost all machine learning algorithms used today. We need to get familiar with the interface of the library to understand how it can be used in practice. Further in the course we will not only use ready-made implementations from sklearn, but sometimes we will implement algorithms ourselves in the same spirit as in this library (with the same interface).\n",
        "\n",
        "To implement machine learning algorithms in sklearn, one interface is always used - a class with the `fit(X, Y)` method for training the model on the training sample $X, Y$ and predict(X) for returning predictions on the sample $X$. When creating a class, you can specify additional parameters that affect the operation of the machine learning algorithm.\n",
        "\n",
        "For example, this would be the logic of the linear regression class, which we will explore in detail during the next seminars:\n",
        "\n",
        "* When creating the class, we need to remember the regularization coefficient;\n",
        "* The purpose of the `fit` function is to find the weights w from the sample $X$ and $Y$ and store them inside the class as self.w;\n",
        "* The purpose of the `predict` function is to return the predictions of $Y$ according to the weights of self.w and $X$.\n",
        "\n",
        "\n",
        "$$w = (X^TX + \\lambda E)^{-1}X^Ty$$\n",
        "\n",
        "### Seminar Agenda\n",
        "- Data preprocessing using scikit-learn\n",
        "        - handling missing values\n",
        "        - <handling outliers>\n",
        "        - converting categorical features to numeric\n",
        "        - feature scaling\n",
        "- Distance-based methods. k Nearest Neighbors\n",
        "        - Theory part\n",
        "        - Practical part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "678G0Zm7wt40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKZ77KDtwt41"
      },
      "outputs": [],
      "source": [
        "class LinearRegressor:\n",
        "    def __init__(self, reg_coef: float = None) -> None:\n",
        "        self.lambda_ = reg_coef\n",
        "\n",
        "    def fit(self, X_train: np.array, y_train: np.array) -> None:\n",
        "        self.w = ...\n",
        "\n",
        "    def predict(self, X_test: np.array) -> np.array:\n",
        "        y_pred = ...\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaF4owlBwt41"
      },
      "source": [
        "If we didn't use a class, we would have to pass the weights `w` to the `predict` function every time we wanted to make predictions, whereas this way they are stored inside the class. This is especially useful if there are many such auxiliary variables.\n",
        "\n",
        "In addition to training and prediction algorithms for different methods, sklearn implements a lot of auxiliary functionality for data preprocessing, data visualization, computing quality metrics, etc. In the following seminars, we will gradually get to know this functionality of the library.\n",
        "\n",
        "Today we will learn about data preprocessing methods and their implementation in sklearn. For demonstrations, we will load the [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). The data contains categorical, integer and real-valued attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMxmONMxwt41",
        "outputId": "e7e98d92-11bd-4096-e751-02bfd40f867b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>...</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>13495.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>...</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>94.5</td>\n",
              "      <td>...</td>\n",
              "      <td>152</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>164.0</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>...</td>\n",
              "      <td>109</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>5500.0</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>164.0</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.4</td>\n",
              "      <td>...</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>5500.0</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0      1            2    3    4     5            6    7      8     9   ...  \\\n",
              "0   3    NaN  alfa-romero  gas  std   two  convertible  rwd  front  88.6  ...   \n",
              "1   3    NaN  alfa-romero  gas  std   two  convertible  rwd  front  88.6  ...   \n",
              "2   1    NaN  alfa-romero  gas  std   two    hatchback  rwd  front  94.5  ...   \n",
              "3   2  164.0         audi  gas  std  four        sedan  fwd  front  99.8  ...   \n",
              "4   2  164.0         audi  gas  std  four        sedan  4wd  front  99.4  ...   \n",
              "\n",
              "    16    17    18    19    20     21      22  23  24       25  \n",
              "0  130  mpfi  3.47  2.68   9.0  111.0  5000.0  21  27  13495.0  \n",
              "1  130  mpfi  3.47  2.68   9.0  111.0  5000.0  21  27  16500.0  \n",
              "2  152  mpfi  2.68  3.47   9.0  154.0  5000.0  19  26  16500.0  \n",
              "3  109  mpfi  3.19  3.40  10.0  102.0  5500.0  24  30  13950.0  \n",
              "4  136  mpfi  3.19  3.40   8.0  115.0  5500.0  18  22  17450.0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_raw = pd.read_csv(\n",
        "    \"http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\",\n",
        "    header=None,\n",
        "    na_values=[\"?\"],\n",
        ")\n",
        "X_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBSlVTU1wt41"
      },
      "source": [
        "Let's separate the attributes and the target variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGGUA2HNwt41"
      },
      "outputs": [],
      "source": [
        "y = X_raw[25]\n",
        "X_raw = X_raw.drop(25, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKEWIjHOwt42"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "### Filling the gaps\n",
        "In a feature matrix, there may be missing values, which can cause an error when passing the matrix to a model training function or even to a preprocessing step. If there are only a few missing values, one option is to remove the corresponding samples from the training set. Alternatively, the missing values can be filled in using various techniques:\n",
        "\n",
        "- filling with summary statistics (mean or median);\n",
        "- predicting missing values based on the observed features.\n",
        "\n",
        "\n",
        "The second approach is more complex and less commonly used. For filling with constant values, you can use the fillna method of a DataFrame. To replace missing values with the mean or other statistics, use the  `impute.SimpleImputer`   class\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEkrWj1rwt42"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP_w90Crwt42",
        "outputId": "0763f65e-489b-4bef-9be5-ad101c002f1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>...</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>...</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>mpfi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>...</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>mpfi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>...</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>ohcv</td>\n",
              "      <td>six</td>\n",
              "      <td>mpfi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>...</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>mpfi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>...</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>ohc</td>\n",
              "      <td>five</td>\n",
              "      <td>mpfi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0      1     9      10    11    12      13     16    18    19  ...  \\\n",
              "0  3.0  122.0  88.6  168.8  64.1  48.8  2548.0  130.0  3.47  2.68  ...   \n",
              "1  3.0  122.0  88.6  168.8  64.1  48.8  2548.0  130.0  3.47  2.68  ...   \n",
              "2  1.0  122.0  94.5  171.2  65.5  52.4  2823.0  152.0  2.68  3.47  ...   \n",
              "3  2.0  164.0  99.8  176.6  66.2  54.3  2337.0  109.0  3.19  3.40  ...   \n",
              "4  2.0  164.0  99.4  176.6  66.4  54.3  2824.0  136.0  3.19  3.40  ...   \n",
              "\n",
              "            2    3    4     5            6    7      8     14    15    17  \n",
              "0  alfa-romero  gas  std   two  convertible  rwd  front  dohc  four  mpfi  \n",
              "1  alfa-romero  gas  std   two  convertible  rwd  front  dohc  four  mpfi  \n",
              "2  alfa-romero  gas  std   two    hatchback  rwd  front  ohcv   six  mpfi  \n",
              "3         audi  gas  std  four        sedan  fwd  front   ohc  four  mpfi  \n",
              "4         audi  gas  std  four        sedan  4wd  front   ohc  five  mpfi  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To make working with our dataset easier, we create a mask that identifies the columns with categorical features.\n",
        "# Categorical features typically have the data type \"object\"\n",
        "cat_features_mask = (X_raw.dtypes == \"object\").values\n",
        "\n",
        "# For numerical features, we'll fill in the missing values using the mean.\n",
        "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
        "mis_replacer = SimpleImputer(strategy=\"mean\")\n",
        "X_no_mis_real = pd.DataFrame(\n",
        "    data=mis_replacer.fit_transform(X_real), columns=X_real.columns\n",
        ")\n",
        "\n",
        "# For categorical features, we'll fill in the missing values with empty strings.\n",
        "X_cat = X_raw[X_raw.columns[cat_features_mask]].fillna(\"\")\n",
        "X_no_mis = pd.concat([X_no_mis_real, X_cat], axis=1)\n",
        "\n",
        "X_no_mis.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beWSSA41wt42"
      },
      "source": [
        "It’s always important to analyze whether the missing values in a feature occur randomly. Sometimes, the very fact that information is missing can be a valuable signal that should be turned into a new feature.\n",
        "\n",
        "__Example:__ predicting a user’s age based on data from their phone. Older users tend to use simpler phones, so the absence of certain data (like browsing history) may actually be a strong indicator of age.\n",
        "\n",
        "For categorical features, it's often recommended to introduce a separate category to represent missing values. In our case, there are no missing values in the categorical features.\n",
        "\n",
        "### Converting categorical features to numerical format\n",
        "Almost all machine learning algorithms require the input to the training function to be a numerical (float) matrix. During training, the algorithms rely on properties of real numbers — such as the ability to compare values and perform arithmetic operations. Therefore, even if the feature matrix contains numeric-looking values, it's important to assess whether they should actually be treated as numerical features.\n",
        "\n",
        "__Example:__ Some features may be represented as integer hashes or IDs (for example, a social media user ID). However, you can’t add two users and get a third one based on their IDs — but that’s exactly the kind of operation a linear model might try to perform if it treats IDs as numerical features.\n",
        "\n",
        "This is an example of a categorical feature that takes values from an unordered, finite set $K$. A common approach for such features is to apply [one-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features), which replaces the original feature with $K$ binary features — one for each possible category value. In `sklearn`, this can be done using the `LabelEncoder` and `OneHotEncoder` classes, but it's often easier to use the `pd.get_dummies` function.\n",
        "\n",
        "Note that the resulting matrix will contain a lot of zeros. To avoid storing them in memory, you can set the parameter `OneHotEncoder` or `.get_dummies`, and the method will return a [sparse matrix](http://docs.scipy.org/doc/scipy/reference/sparse.html), which only stores the non-zero values. While some operations on sparse matrices can be inefficient, most `sklearn` methods support working with sparse input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI8piZI7wt42",
        "outputId": "a400420d-a879-48fc-ddf5-802bbddc2ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape before encoding: (205, 25)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>...</th>\n",
              "      <th>15_three</th>\n",
              "      <th>15_twelve</th>\n",
              "      <th>15_two</th>\n",
              "      <th>17_2bbl</th>\n",
              "      <th>17_4bbl</th>\n",
              "      <th>17_idi</th>\n",
              "      <th>17_mfi</th>\n",
              "      <th>17_mpfi</th>\n",
              "      <th>17_spdi</th>\n",
              "      <th>17_spfi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>2952.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.8</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3049.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3012.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>3.58</td>\n",
              "      <td>2.87</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3217.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>3.01</td>\n",
              "      <td>3.40</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3062.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0      1      9     10    11    12      13     16    18    19  ...  \\\n",
              "0    3.0  122.0   88.6  168.8  64.1  48.8  2548.0  130.0  3.47  2.68  ...   \n",
              "1    3.0  122.0   88.6  168.8  64.1  48.8  2548.0  130.0  3.47  2.68  ...   \n",
              "2    1.0  122.0   94.5  171.2  65.5  52.4  2823.0  152.0  2.68  3.47  ...   \n",
              "3    2.0  164.0   99.8  176.6  66.2  54.3  2337.0  109.0  3.19  3.40  ...   \n",
              "4    2.0  164.0   99.4  176.6  66.4  54.3  2824.0  136.0  3.19  3.40  ...   \n",
              "..   ...    ...    ...    ...   ...   ...     ...    ...   ...   ...  ...   \n",
              "200 -1.0   95.0  109.1  188.8  68.9  55.5  2952.0  141.0  3.78  3.15  ...   \n",
              "201 -1.0   95.0  109.1  188.8  68.8  55.5  3049.0  141.0  3.78  3.15  ...   \n",
              "202 -1.0   95.0  109.1  188.8  68.9  55.5  3012.0  173.0  3.58  2.87  ...   \n",
              "203 -1.0   95.0  109.1  188.8  68.9  55.5  3217.0  145.0  3.01  3.40  ...   \n",
              "204 -1.0   95.0  109.1  188.8  68.9  55.5  3062.0  141.0  3.78  3.15  ...   \n",
              "\n",
              "     15_three  15_twelve  15_two  17_2bbl  17_4bbl  17_idi  17_mfi  17_mpfi  \\\n",
              "0           0          0       0        0        0       0       0        1   \n",
              "1           0          0       0        0        0       0       0        1   \n",
              "2           0          0       0        0        0       0       0        1   \n",
              "3           0          0       0        0        0       0       0        1   \n",
              "4           0          0       0        0        0       0       0        1   \n",
              "..        ...        ...     ...      ...      ...     ...     ...      ...   \n",
              "200         0          0       0        0        0       0       0        1   \n",
              "201         0          0       0        0        0       0       0        1   \n",
              "202         0          0       0        0        0       0       0        1   \n",
              "203         0          0       0        0        0       1       0        0   \n",
              "204         0          0       0        0        0       0       0        1   \n",
              "\n",
              "     17_spdi  17_spfi  \n",
              "0          0        0  \n",
              "1          0        0  \n",
              "2          0        0  \n",
              "3          0        0  \n",
              "4          0        0  \n",
              "..       ...      ...  \n",
              "200        0        0  \n",
              "201        0        0  \n",
              "202        0        0  \n",
              "203        0        0  \n",
              "204        0        0  \n",
              "\n",
              "[205 rows x 66 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"Shape before encoding: {X_no_mis.shape}\")\n",
        "X_dum = pd.get_dummies(X_no_mis, drop_first=True)\n",
        "X_dum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Y3ZlF2wt43"
      },
      "source": [
        "In addition to categorical features, string features also require transformation. They can be converted into a word frequency matrix using [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), into a matrix of fixed-length character n-gram frequencies, or used to extract other features — such as the length of the string.\n",
        "\n",
        "### Feature scaling\n",
        "When working with data, it's always recommended to bring all features to the same scale. This is important for numerical stability when dealing with the feature matrix, since floating-point numbers are more densely distributed near zero than in the range of large values. Additionally, many machine learning algorithms have specific requirements that make feature scaling necessary. For example, in linear models, scaling helps speed up training and improves model interpretability.\n",
        "\n",
        "One popular scaling method is normalization: subtracting the mean and dividing by the standard deviation for each feature (`StandardScaler` in `sklearn`). Another common approach is min-max scaling: subtracting the minimum and dividing by the range (max - min) of each feature (`MinMaxScaler` in `sklearn`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zohOAwPGwt43",
        "outputId": "da282b84-300e-4868-cb95-42ac770d7bdf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.298429</td>\n",
              "      <td>0.058309</td>\n",
              "      <td>0.413433</td>\n",
              "      <td>0.316667</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.411171</td>\n",
              "      <td>0.260377</td>\n",
              "      <td>0.664286</td>\n",
              "      <td>0.290476</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.298429</td>\n",
              "      <td>0.058309</td>\n",
              "      <td>0.413433</td>\n",
              "      <td>0.316667</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.411171</td>\n",
              "      <td>0.260377</td>\n",
              "      <td>0.664286</td>\n",
              "      <td>0.290476</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.298429</td>\n",
              "      <td>0.230321</td>\n",
              "      <td>0.449254</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.383333</td>\n",
              "      <td>0.517843</td>\n",
              "      <td>0.343396</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.518325</td>\n",
              "      <td>0.384840</td>\n",
              "      <td>0.529851</td>\n",
              "      <td>0.491667</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.329325</td>\n",
              "      <td>0.181132</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.518325</td>\n",
              "      <td>0.373178</td>\n",
              "      <td>0.529851</td>\n",
              "      <td>0.508333</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.518231</td>\n",
              "      <td>0.283019</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0         1         2         3         4         5         6         7   \\\n",
              "0  1.0  0.298429  0.058309  0.413433  0.316667  0.083333  0.411171  0.260377   \n",
              "1  1.0  0.298429  0.058309  0.413433  0.316667  0.083333  0.411171  0.260377   \n",
              "2  0.6  0.298429  0.230321  0.449254  0.433333  0.383333  0.517843  0.343396   \n",
              "3  0.8  0.518325  0.384840  0.529851  0.491667  0.541667  0.329325  0.181132   \n",
              "4  0.8  0.518325  0.373178  0.529851  0.508333  0.541667  0.518231  0.283019   \n",
              "\n",
              "         8         9   ...   56   57   58   59   60   61   62   63   64   65  \n",
              "0  0.664286  0.290476  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "1  0.664286  0.290476  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "2  0.100000  0.666667  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "3  0.464286  0.633333  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "4  0.464286  0.633333  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "\n",
              "[5 rows x 66 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "normalizer = preprocessing.MinMaxScaler()\n",
        "X_real_norm_np = normalizer.fit_transform(X_dum)\n",
        "X = pd.DataFrame(data=X_real_norm_np)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H-Vl7KAwt43"
      },
      "source": [
        "#### Realization Example\n",
        "\n",
        "Let's implement a class for data normalization, following the interface style of `sklearn`.\n",
        "\n",
        "In `sklearn`, data preprocessing follows a pattern similar to model training: the `.fit(X)` function stores internal parameters, and `.transform(X)` performs the transformation on the dataset. The target variable `y` is not needed here, since normalization does not involve the target — as is the case with most preprocessing steps.\n",
        "\n",
        "This class doesn’t require any parameters, so we can skip the `__init__` method. The `.fit()` function calculates statistics — the mean and standard deviation of each feature (based on the training data), and the `.transform()` function subtracts the mean and divides by the standard deviation. We’ll use NumPy to compute the statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgauFz-hwt43"
      },
      "outputs": [],
      "source": [
        "class Normalizer:\n",
        "    def fit(self, X: np.array) -> None:\n",
        "        self.mu = X.mean(axis=0)\n",
        "        self.sigma = X.std(axis=0)\n",
        "\n",
        "    def transform(self, X: np.array) -> np.array:\n",
        "        return (X - self.mu[np.newaxis, :]) / self.sigma[np.newaxis, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9SUgN7Vwt43"
      },
      "source": [
        "Let’s generate some random data `X` and `y` to test our class:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZukME5k7wt43",
        "outputId": "50966f8e-18d7-4450-ed07-a639422e373d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 4)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_obj_train = 20\n",
        "num_obj_te = 10\n",
        "num_feat = 4\n",
        "X_train = np.random.randint(-5, 5, size=(num_obj_train, num_feat))\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NlLmWIhwt43",
        "outputId": "5a4fa947-65de-4ab8-fc12-2ddc97613e7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 4)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test = np.random.randint(-5, 5, size=(num_obj_te, num_feat))\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etkyjZ6_wt43",
        "outputId": "adf6b584-78a2-4863-c679-ebd9e98a3a91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  2,  2, -3],\n",
              "       [-2,  4,  4, -3],\n",
              "       [-5, -2, -3, -3],\n",
              "       [-5,  3, -1,  4],\n",
              "       [ 4, -3,  3, -5],\n",
              "       [-5,  1,  4,  2],\n",
              "       [-1, -1, -5, -1],\n",
              "       [-2, -1, -1,  1],\n",
              "       [ 0,  4, -3,  0],\n",
              "       [ 4, -4,  0,  0],\n",
              "       [-3, -3,  4, -3],\n",
              "       [ 1,  0,  2, -5],\n",
              "       [-5,  2,  1,  2],\n",
              "       [-3, -1, -3,  4],\n",
              "       [-1, -1, -3, -4],\n",
              "       [-1,  3, -4,  0],\n",
              "       [-4,  4, -4,  0],\n",
              "       [-4,  3, -1,  1],\n",
              "       [-1,  0, -2,  2],\n",
              "       [ 3,  1,  4,  1]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ikwqF_lwt44"
      },
      "source": [
        "We create an instance of the class and transform the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wa6x-zwwt44"
      },
      "outputs": [],
      "source": [
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_train)\n",
        "X_train_transformed = normalizer.transform(X_train)\n",
        "X_test_transformed = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbFm43Lwt44"
      },
      "source": [
        "The `fit` method should be called specifically on the training data to avoid leaking information from the validation set. The `transform` method, on the other hand, can be called multiple times on any dataset, using the statistics already computed and stored inside the class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzX40rrIwt44",
        "outputId": "0c98afe5-4771-4405-9a1a-1d62f07e451e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.53199518,  0.58963067,  0.7662411 , -0.92847669],\n",
              "       [-0.17733173,  1.40291435,  1.4325377 , -0.92847669],\n",
              "       [-1.24132208, -1.03693669, -0.89950042, -0.92847669],\n",
              "       [-1.24132208,  0.99627251, -0.23320381,  1.67125804],\n",
              "       [ 1.95064898, -1.44357853,  1.0993894 , -1.67125804],\n",
              "       [-1.24132208,  0.18298883,  1.4325377 ,  0.92847669],\n",
              "       [ 0.17733173, -0.63029485, -1.56579702, -0.18569534],\n",
              "       [-0.17733173, -0.63029485, -0.23320381,  0.55708601],\n",
              "       [ 0.53199518,  1.40291435, -0.89950042,  0.18569534],\n",
              "       [ 1.95064898, -1.85022037,  0.09994449,  0.18569534],\n",
              "       [-0.53199518, -1.44357853,  1.4325377 , -0.92847669],\n",
              "       [ 0.88665863, -0.22365301,  0.7662411 , -1.67125804],\n",
              "       [-1.24132208,  0.58963067,  0.43309279,  0.92847669],\n",
              "       [-0.53199518, -0.63029485, -0.89950042,  1.67125804],\n",
              "       [ 0.17733173, -0.63029485, -0.89950042, -1.29986737],\n",
              "       [ 0.17733173,  0.99627251, -1.23264872,  0.18569534],\n",
              "       [-0.88665863,  1.40291435, -1.23264872,  0.18569534],\n",
              "       [-0.88665863,  0.99627251, -0.23320381,  0.55708601],\n",
              "       [ 0.17733173, -0.22365301, -0.56635211,  0.92847669],\n",
              "       [ 1.59598553,  0.18298883,  1.4325377 ,  0.55708601]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_transformed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0VFXEwywt44"
      },
      "source": [
        "## Distance-based methods: k Nearest Neighbours (k-NN)\n",
        "\n",
        "### Theoretical Overview\n",
        "\n",
        "__Recall from the last year:__  \n",
        "* How are predictions made in the k Nearest Neighbours method for classification and regression tasks?  \n",
        "* What is the compactness hypothesis?  \n",
        "* What distance functions can be used for numerical features, categorical features, string features, and multi-valued features?\n",
        "\n",
        "#### Task 1.  \n",
        "Suppose we are solving a 3-class classification problem using two features and the k Nearest Neighbours method with *k = 3* and the Manhattan distance metric. We have the following training dataset:\n",
        "\n",
        "| Feature 1 | Feature 2 | Class |\n",
        "|-----------|-----------|-------|\n",
        "| 1         | -1        | 1     |\n",
        "| 2         | 2         | 1     |\n",
        "| 3         | 2         | 2     |\n",
        "| 1         | 0         | 3     |\n",
        "| 2         | -2        | 3     |\n",
        "\n",
        "What would the prediction be for the object $x = (2, -1)$?\n",
        "\n",
        "__Solution.__\n",
        "\n",
        "The prediction algorithm for kNN in a classification task:  \n",
        "1. Compute the distance from each training sample to the test object.  \n",
        "2. Find the *k* training samples (neighbors) with the smallest distances to the test object.  \n",
        "3. Return the most frequently occurring class among the *k* neighbors.\n",
        "\n",
        "Let's compute the distances. The distance from the first training sample to the test object $x$ using the Manhattan metric is:\n",
        "\n",
        "$$|1 - 2| + |-1 - (-1)| = 1.$$\n",
        "\n",
        "Similarly, for samples 2 to 5, we get distances of 3, 4, 2, and 1, respectively.\n",
        "\n",
        "The 3 nearest neighbors are samples 1, 4, and 5 (with distances 1, 2, and 1). These correspond to classes 1, 3, and 3. The most frequent class among them is 3, so the predicted class is **3**.\n",
        "\n",
        "#### Task 2.  \n",
        "Visualize the decision boundary between classes for the following dataset:\n",
        "\n",
        "| Feature 1 | Feature 2 | Class |\n",
        "|-----------|-----------|-------|\n",
        "| 2         | 2         | 1     |\n",
        "| 3         | 2         | 1     |\n",
        "| 2         | 0         | 2     |\n",
        "| 1         | -1        | 3     |\n",
        "| 1         | 1         | 3     |\n",
        "\n",
        "Use *k = 1* and the Euclidean distance.\n",
        "\n",
        "__Solution.__\n",
        "\n",
        "In classification problems with two features, we can visualize the feature space as a 2D plane and color it based on the predicted class for each point. That’s exactly our task here.\n",
        "\n",
        "First, let's plot the training samples — five points — on the plane according to their coordinates.\n",
        "\n",
        "With $k = 1$, each point in the plane is assigned the same class as its nearest neighbor from the training set. When we have two points from different classes, the class boundary between them is defined by the perpendicular bisector. For multiple points, we construct several such bisectors, find their intersections, and determine which regions correspond to which class. This structure is formally known as a [Voronoi diagram](https://en.wikipedia.org/wiki/Voronoi_diagram), although we won’t go into its mathematical details here.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/hse-ds/iad-intro-ds/blob/master/2023/seminars/sem05_sklearn_knn/static/classifi.png?raw=true\" width=\"350\"/>\n",
        "</div>\n",
        "\n",
        "#### Task 3.  \n",
        "Suppose we are solving a regression problem with two features using the k Nearest Neighbours method with *k = 3* and the Manhattan distance metric. We have the following training dataset:\n",
        "\n",
        "| Feature 1 | Feature 2 | Target |\n",
        "|-----------|-----------|--------|\n",
        "| 1         | -1        | 3.5    |\n",
        "| 2         | 2         | 2.3    |\n",
        "| 3         | 2         | 1.7    |\n",
        "| 1         | 0         | -0.4   |\n",
        "| 2         | -2        | 0.1    |\n",
        "\n",
        "What would the prediction be for the object $x = (2, -1)$?\n",
        "\n",
        "__Solution.__  \n",
        "The prediction process for kNN in regression differs from classification only in the final step: instead of taking the most frequent class, we average the target values of the nearest neighbors.  \n",
        "The features in this task are the same as in Task 1, so we already know the nearest neighbors: samples 1, 4, and 5. Their target values are 3.5, -0.4, and 0.1.  \n",
        "\n",
        "Let’s compute the average:  \n",
        "$$(3.5 - 0.4 + 0.1)/3 = 1.1$$  \n",
        "So, the predicted value is **1.1**.\n",
        "\n",
        "#### Question: What are the parameters and hyperparameters of the kNN method?\n",
        "\n",
        "__Answer:__\n",
        "\n",
        "**Parameters** are values adjusted during training using the training data. The kNN algorithm doesn’t involve actual training — it’s a very simple heuristic method. In this context, the parameters of kNN can be interpreted as the training dataset itself. In another interpretation, the method has no parameters at all.\n",
        "\n",
        "**Hyperparameters** are values that must be set before training the model. They are not learned from the training data. The two most important hyperparameters of the kNN method are the number of neighbors *k* and the distance metric. Different combinations of these hyperparameters can result in very different performance. Hyperparameters are typically tuned using a validation set or cross-validation.\n",
        "\n",
        "\n",
        "#### How does kNN performance change as *k* increases?\n",
        "\n",
        "__Answer:__\n",
        "\n",
        "When $k=1$, each training sample defines its own class region. If, for example, a single noisy sample of a different class ends up in a large region of another class, there will be an \"island\" of incorrect predictions around this noisy point. This is illogical and indicates overfitting.\n",
        "\n",
        "When $k$ equals the number of training samples, the model predicts the same class for all points — again, this results in poor classifier performance. This means that kNN accuracy usually increases at first as $k$ grows, then decreases, with the optimal value somewhere in between.\n",
        "\n",
        "Consider a synthetic example: the training set is visualized below (the “true” decision boundary is a straight line), along with kNN decision boundaries for different values of $k$ — similar to Task 2:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/hse-ds/iad-intro-ds/blob/master/2023/seminars/sem05_sklearn_knn/static/k_grid.png?raw=true\" width=\"550\"/>\n",
        "</div>\n",
        "\n",
        "With small $k$, the decision boundary is too complex and heavily influenced by noise. As $k$ increases, the boundary becomes smoother, and at $k=50$ it looks the most reasonable. For even larger $k$, the boundary drifts away from linear, and the orange class starts to “invade” the blue region.\n",
        "\n",
        "#### Why is it important to normalize data when using kNN?\n",
        "\n",
        "__Answer:__\n",
        "\n",
        "Let’s take the Manhattan distance as an example. If one feature has values on the scale of around 1000, while another is around 1, then when we compute the sum of absolute differences, the second feature will have almost no influence on the result. However, if we normalize the features, they will all be on the same scale and contribute equally to the distance calculation.\n",
        "\n",
        "\n",
        "### Practical Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpt1MXEGwt45"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ngYFfMowt45",
        "outputId": "0c2bba45-9fd2-4c39-b7c9-7e2d57292082"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1797, 8, 8)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = load_digits()\n",
        "X = data.images\n",
        "y = data.target\n",
        "\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBVSGMqCwt46",
        "outputId": "75416193-f7d4-4292-d079-c04ee4fd96ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: (1797, 64),\n",
            "Target shape: (1797,)\n",
            "Target samples: [0 6 3 4 5 8 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "# We flatten each square image into a vector to obtain a feature matrix (samples × features).\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# We shuffle the data.\n",
        "X, y = shuffle(X, y)\n",
        "print(f\"Features shape: {X.shape},\\nTarget shape: {y.shape}\")\n",
        "print(f\"Target samples: {y[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkMrn89Swt47"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = X[:700, :], y[:700]\n",
        "X_val, y_val = X[700:1300, :], y[700:1300]\n",
        "X_test, y_test = X[1300:, :], y[1300:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2ndbGwKwt47"
      },
      "outputs": [],
      "source": [
        "# We train the classifier and make predictions.\n",
        "clf = KNeighborsClassifier(n_neighbors=3, p=1, n_jobs=10)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_predicted = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY1l9uaHwt47",
        "outputId": "65034e84-d2b7-4860-a8ed-5e5f19ace33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is:  0.9859154929577465\n"
          ]
        }
      ],
      "source": [
        "# We compute the simplest quality metric for the algorithm — the accuracy\n",
        "print(\"Accuracy is: \", np.mean(y_test == y_predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5TPSTfwt47"
      },
      "source": [
        "Given that we have 10 classes, the chance of randomly guessing the correct label multiple times is very low. So the obtained accuracy is actually a very good result!\n",
        "\n",
        "Now let’s try using different values of the hyperparameter *k*.  \n",
        "Comparing *k* values on the training set is pointless: each sample is its own nearest neighbor, so the optimal *k* would always be 1.  \n",
        "Instead, we’ll compare different *k* values based on validation set performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20gQdXtCwt47",
        "outputId": "914b42e5-880e-48ce-8f7f-0494b1ca7709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k = 1; accuracy = 0.975\n",
            "k = 2; accuracy = 0.967\n",
            "k = 3; accuracy = 0.977\n",
            "k = 4; accuracy = 0.968\n",
            "k = 5; accuracy = 0.972\n",
            "k = 6; accuracy = 0.968\n",
            "k = 7; accuracy = 0.967\n",
            "k = 8; accuracy = 0.965\n",
            "k = 9; accuracy = 0.963\n",
            "k = 10; accuracy = 0.963\n",
            "k = 11; accuracy = 0.968\n",
            "k = 12; accuracy = 0.958\n",
            "k = 13; accuracy = 0.957\n",
            "k = 14; accuracy = 0.958\n",
            "k = 15; accuracy = 0.958\n",
            "k = 16; accuracy = 0.957\n",
            "k = 17; accuracy = 0.952\n",
            "k = 18; accuracy = 0.953\n",
            "k = 19; accuracy = 0.947\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tuning k using the validation set:\n",
        "k_best = -1\n",
        "best_accuracy = 0\n",
        "\n",
        "for k in range(1, 20):\n",
        "    y_predicted = (\n",
        "        KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train).predict(X_val)\n",
        "    )\n",
        "\n",
        "    val_accuracy = np.mean(y_predicted == y_val)\n",
        "    print(f\"k = {k}; accuracy = {val_accuracy:.3f}\")\n",
        "\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        k_best = k\n",
        "\n",
        "k_best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkpizJmuwt47"
      },
      "source": [
        "Let’s compare the accuracy on the training, validation, and test sets using the best *k* value we found:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugzOrNFEwt48",
        "outputId": "7d83f35c-7937-4afd-a293-1935e77bd215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.993\n",
            "Accuracy: 0.977\n",
            "Accuracy: 0.990\n"
          ]
        }
      ],
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=k_best)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "for X_data, y_data in zip([X_train, X_val, X_test], [y_train, y_val, y_test]):\n",
        "    y_predicted = clf.predict(X_data)\n",
        "    print(f\"Accuracy: {np.mean(y_predicted==y_data):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVpT8D43wt48"
      },
      "source": [
        "Training set accuracy is the highest, but it's misleading — the algorithm has already seen these samples. On the validation set, we also used the true labels to tune the hyperparameter *k*, so this metric isn’t entirely fair either. In fact, the accuracy on the test set — where we haven’t used the labels at all — may turn out to be lower than on the validation set.\n",
        "\n",
        "**Conclusion:**  \n",
        "To fairly evaluate model performance, we should use a **hold-out test set** that is not involved in training or hyperparameter tuning in any way."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}