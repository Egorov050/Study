Фундаментальный принцип бутстрапа заключается в использовании `повторной выборки с возвращением из исходных данных для создания множества выборок (бутстрап-выборок)`. Этот метод позволяет оценивать статистики, такие как среднее, дисперсия или доверительные интервалы, даже в тех случаях, когда `нет явных предположений о распределении данных`. Единственная предпосылка, которая нужна для бутстрапа это большое количество наблюдений. Также стоит отметить, что бутстрап это `асимптотическая техника`, но с цпт она не имеет никакой связи. 
<h6>Суть</h6>
У нас есть определенная выборка, она большая и состоит из `n` элементов.  Она настолько большая, что мы можем из нее получить бутстраповские выборки , которые будут иметь такую же размерность `n` . Таких выборок мы можем сделать `b` штук, при этом у каждой выборки мы считаем тот параметр, который нам интересен. Будь то это медиана или иная штука. Также стоит отметить, что повторения нас тоже устраивают. 

Работа с бутстрапом это работа как с доверительным интервалом , так и с p-value. Есть три способа как сформировать этот доверительный интервал. Рассмотрим каждый из них. 
<h6>Эфронов доверительный интервал ( Перцентильный ) </h6>

Итак, пусть у нас есть выборка  ${x_1}$, ${x_2}$, ${x_3}$ ... ${x_n}$

`Первое` , что мы делаем это Из нее мы генерируем `b` количество выборок  и для каждой выборки мы считаем нашу метрику ( *в нашем случае это медиана* ):

- sample 1 : ${x_1}$, ${x_2}$, ${x_3}$ ... ${x_n}$  ,  ${med_1}$
- sample 2 : ${x_1}$, ${x_2}$, ${x_3}$ ... ${x_n}$ ,  ${med_2}$
- sample 3 : ${x_1}$, ${x_2}$, ${x_3}$ ... ${x_n}$ ,  ${med_3}$
- ....................................................
- sample b : ${x_1}$, ${x_2}$, ${x_3}$ ... ${x_n}$ ,  ${med_b}$

`Второе`, что мы делаем это мы нашу метрику ( *в нашем случае медианы* )  выборок загоняем в массив и строим гистограмму. 

`Третье` , основываясь на полученном распределении мы определяем  $alpha$ - процентиль и $1 -alpha$ процентиль для распределения статистик, полученных из бутстрап-выборок. Здесь $alpha$ - это уровень значимости (например, для 95% доверительного интервала $alpha$ = 0.025). И далее строим доверительный интервал : 

$$
(\theta_{\text{lower}}, \theta_{\text{upper}}) = (\theta_{\alpha}, \theta_{1 - \alpha})
$$

Как это делается на питоне. Давайте предположим что у нас есть две выборки и мы хотим проверить , равны ли медианы этих выборок или нет .  То есть нулевая гипотеза говорит о том, что медианы равны. Альтернативная гипотеза, что медианы не равны. Соотвественно, в первом варианте мы проверим при помощи доверительного интервала.
<h6>Первый шаг</h6>`Для начала давайте напишем функцию, которая будет генерировать наши бутстрап семплы` : 


```python

def get_bootstrap_sample(x, B_sample=1):
    N = x.size 
    sample = np.random.choice(x, size=(B_sample, N), replace=True)
    
    if B_sample == 1:
        sample = sample.T[0]
    return sample 
    
```

Эта функция позволяет генерировать бутстрап семплы , например : 

```python
# предположим что у нас есть две выборки, тестовая и контрольная : 
values_a = np.random.normal(90, 20, 10000)
values_b = np.random.normal(90, 15, 10000)

# при помощи функции сгенирируем бутстрап выборки : 

bootstrap_samples_a = get_bootstrap_sample(values_a, B_sample=10000)
bootstrap_samples_b = get_bootstrap_sample(values_b, B_sample=10000)

```

Стоит отметить :  Использование `replace=True` в функции `np.random.choice` позволяет выбирать каждый элемент с возвращением. Это означает, что после выбора элемента из массива `x` он не удаляется из возможных последующих выборок. В результате, один и тот же элемент может быть выбран несколько раз, а некоторые элементы могут не попасть в выборку вовсе. Это обеспечивает независимость каждого выбранного элемента и позволяет создать бутстрап-выборку того же размера, что и исходная выборка . 

Далее в рамках первого шага мы высчитываем медиану для каждой выборки : 

```python
bootstrap_samples_a_m = np.median(bootstrap_samples_a, axis = 1)
bootstrap_samples_b_m = np.median(bootstrap_samples_b, axis = 1)
```

Далее переходим ко `второму шагу`.  Так как нас интересует разница между медианами, так как именно для разницы мы строим доверительный интервал, то мы должны посчитать эту разницу между семплами. И уже для этой разницы мы будем строить доверительный интервал. Если нуль ( а это и есть нулевая гипотеза ) лежит в нашем доверительном интервале, то в таком случае мы не отклоняем нулевую гипотезу. В противном случае , мы ее отклоняем. 

Посчитаем разницу и визуализируем : 

```python
result = bootstrap_samples_a_m - bootstrap_samples_b_m

plt.hist(result, bins=40)
plt.show()
```

<img width="493" alt="Screenshot 2024-07-28 at 00 11 28" src="https://github.com/user-attachments/assets/23e52dea-d97a-4f76-8500-7608f1543b77">


Видим , что наши средние распределены нормально. Посчитаем квантили и это и будет наш доверительный интервал. Возьмем 95% доверительный интервал : 

```python
alpha = 0.05

left = np.quantile(result, alpha/2)
right = np.quantile(result, 1-alpha/2)
left, right

# результаты 
(-0.6122524122880663, 0.6255296296389445)
```

Визуализируем это : 

<img width="477" alt="Screenshot 2024-07-28 at 00 11 48" src="https://github.com/user-attachments/assets/bf4538d7-45c3-49b5-8365-1e92a51bf5c9">

Опираясь на результаты , мы не отклоняем нулевую гипотезу. 

Давайте сделаем тоже самое , только при помощи `p-value` : 






https://www.youtube.com/watch?v=Zki9VMzxcFU

https://www.youtube.com/watch?v=oRCzEPDMPBQ
https://www.youtube.com/watch?v=-zps6hm0nX8&t=1125s


https://www.youtube.com/watch?v=O6FXzCFnJxM&t=3381s



https://github.com/30lm32/ml-ab-testing


https://www.kaggle.com/datasets/podsyp/how-to-do-product-analytics/data
