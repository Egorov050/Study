Мы знаем, что у нас есть два типа ошибок. Это ошибка первого и второго рода. Мы уже рассматривали это в разделе ml [[Метрики ( supervised  learning)]] 

Дак вот, `ошибка первого рода` - это `False Positive`. То есть мы отклоняем значение, которое на самом деле верно. 

`Ошибка второго рода` - это `True negative`. То есть мы принимаем значение как действительное, но при этом оно не верно.  

В рамках тестирование гипотез : `Ошибка первого рода` происходит, когда мы отвергаем нулевую гипотезу, хотя она на самом деле верна. Это ложное положительное заключение. `Ошибка второго рода` происходит, когда мы не отвергаем нулевую гипотезу, хотя альтернативная гипотеза на самом деле верна. Это ложное отрицательное заключение.

Очевидно, что уровень значимости ( α ) напрямую влияет на ошибку первого и второго рода. 

Вспомним, что такое уровень значимости. Уровень значимости _α_ — это пороговое значение, которое мы устанавливаем перед началом теста, и которое определяет, насколько необычными должны быть данные, чтобы отвергнуть _H0._ Если вероятность получить наблюдаемые данные, предполагая, что _H0_ верна, меньше _α_ , то мы отвергаем H0. По дефолту _α_ устанавливается на уровне 0.05. Крч, мы говорим, что доверительный интервал у нас 95% => что уровень значимости 5% то есть 0.05.

Получается так, что если уровень значимости (α) установлен на 0.05, это означает, что есть 5% шанс ошибочно отвергнуть нулевую гипотезу, когда она верна.