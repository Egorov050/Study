Стратификация - это один из способов понижения `SE`.

Предположим , мы проводим аб тест на наших пользователях. Отметим, что у нас есть программа лояльности. И у нас есть информация, какие пользователи зарегистрированы в программе , а какие нет. 

**Ковариата** - метрика, которая коррелирует с целевой метрикой, может быть измерена до эксперимента (строго говоря, нет) и не зависит от других экспериментов. В нашем случае факт регистрации в программе лояльности до эксперимента будет ковариатой. То есть ковариарта - это то, по какому признаку идет стратификация. 

С помощью ковариат можно разделить популяцию на непересекающиеся подмножества, которые будут обладать уникальным набором значений ковариат. Такие подмножества будем называть **стратами**.

В нашем примере будет две страты:

- первая - кто не зарегистрирован в программе лояльности;
- вторая - кто зарегистрирован в программе лояльности.

Посмотрим на исторические данные пользователей этих страт по отдельности. Допустим, мы выяснили, следующую информацию:

- доли страт в популяции равны и составляют 50%;
- средняя выручка за неделю в первой страте равна 2000 рублей, во второй - 3000 рублей;
- стандартные отклонения выручки за неделю равны 625 рублей в обеих стратах. При таких значениях отклонений объединение данных обеих страт будет иметь отклонение около 800 рублей, как было изначально.

![[Pasted image 20240730210141.png]]

Получается, пользователи разных страт имеют разные распределения метрики.

К чему это может привести? Как мы знаем, когда мы рандомно разбиваем выборку, то может получиться так, что количество пользователей первой страты в контрольной группе может оказаться больше чем в экспериментальной, и наоборот. Это может привести к неверным результатам при оценке пилота, так как средние значения метрики в стратах отличаются.

Проведем эксперимент. 

Сгенерируем две страты поровну, как будто у нас 50% пользователей зарегистрировано , а другие 50% нет. Первая страта будет иметь одно распределение, вторая страта другое. Как только мы сгенерируем, объеденим их и проедем два АА теста. Первый, без разделения при формировании контрольной и тестовой выборки на страты, а второй с разделением. 

```python
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats

strata1c = np.random.normal(100, 50, 10000)
strata2c = np.random.normal(150, 45, 10000)
control = np.concatenate((strata1c, strata2c))

massive = []

for i in range(1000):
    group_1 = np.random.choice(control, 10000, replace = True)
    group_2 = np.random.choice(control, 10000, replace = True)

    _, p_value = stats.ttest_ind(group_1,group_2, alternative='two-sided')

    massive.append(p_value < 0.05)
    
np.mean(massive)

# результат : 

0.055
```

А теперь повторим только с делением : 

```python

massivve = []

for i in range(1000):
    group_1_1 = np.random.choice(strata1c, 5000, replace = True)
    group_1_2 = np.random.choice(strata2c, 5000, replace = True)
    control1 = np.concatenate((group_1_1, group_1_2))

    group_2_1 = np.random.choice(strata1c, 5000, replace = True)
    group_2_2 = np.random.choice(strata2c, 5000, replace = True)
    control2 = np.concatenate((group_2_1, group_2_2))

    _, p_value = stats.ttest_ind(control1,control2, alternative='two-sided')

    massivve.append(p_value < 0.05)

np.mean(massivve)

# результат : 

0.022
    
```

Мы видим, что ошибка первого рода сократилась примерно в два раза ( *PS она может сокращаться еще сильнее* )

Давайте сделаем точно также, только глянем на ошибку второго рода , и на распределение ошибок второго рода : 

```python
strata1c = np.random.normal(100, 50, 10000)
strata2c = np.random.normal(150, 45, 10000)
control = np.concatenate((strata1c, strata2c))



strata1t = np.random.normal(100, 50, 10000)
strata2t = np.random.normal(155, 45, 10000)
controlt = np.concatenate((strata1t, strata2t))
```

```python 
result = []

for i in tqdm(range(100)):
    m = []
    
    for i in range(1000):
        group_1 = np.random.choice(control, 10000, replace = True)
        group_2 = np.random.choice(controlt, 10000, replace = True)
    
        _, p_value = stats.ttest_ind(group_1,group_2, alternative='two-sided')
    
        m.append(p_value > 0.05)
        
    result.append(np.mean(m)) 


plt.hist(result)

```

![[Screenshot 2024-07-30 at 23.18.33.png]]

Видим, где находится среднее. Теперь сравним это при стратификации : 

```python

result2 = []


for i in tqdm(range(100)):
    massivve = []
    for i in range(1000):
        group_1_1 = np.random.choice(strata1c, 5000, replace = True)
        group_1_2 = np.random.choice(strata2c, 5000, replace = True)
        control1 = np.concatenate((group_1_1, group_1_2))
    
        group_2_1 = np.random.choice(strata1t, 5000, replace = True)
        group_2_2 = np.random.choice(strata2t, 5000, replace = True)
        control2 = np.concatenate((group_2_1, group_2_2))
    
        _, p_value = stats.ttest_ind(control1,control2, alternative='two-sided')
    
        massivve.append(p_value > 0.05)

    result2.append(np.mean(massivve))

plt.hist(result2)
```

![[Screenshot 2024-07-30 at 23.22.29.png]]

Мы видим, что среднее смещено влево, а значит ошибка второго рода при стратификации также ниже. 

Но если мы хотим сделать так, чтобы у нас уменьшалась только ошибка второго рода, то мы можем делать выводы опираясь на взвешенное среднее и считать t_value : 

```python

import numpy as np

# Стратифицированные данные
strata1c = np.random.normal(100, 50, 10000)
strata2c = np.random.normal(150, 45, 10000)
strata1t = np.random.normal(100, 50, 10000)
strata2t = np.random.normal(155, 45, 10000)

# Веса для страт
weights_control = np.array([len(strata1c), len(strata2c)])
weights_test = np.array([len(strata1t), len(strata2t)])

# Взвешенные средние
weighted_mean_control = (np.mean(strata1c) * weights_control[0] + np.mean(strata2c) * weights_control[1]) / np.sum(weights_control)
weighted_mean_test = (np.mean(strata1t) * weights_test[0] + np.mean(strata2t) * weights_test[1]) / np.sum(weights_test)

# Взвешенные дисперсии (с учетом размера выборки)
var1c = np.var(strata1c, ddof=1)
var2c = np.var(strata2c, ddof=1)
var1t = np.var(strata1t, ddof=1)
var2t = np.var(strata2t, ddof=1)

weighted_var_control = (weights_control[0] * var1c + weights_control[1] * var2c) / np.sum(weights_control)
weighted_var_test = (weights_test[0] * var1t + weights_test[1] * var2t) / np.sum(weights_test)

# t-значение
n_control = np.sum(weights_control)
n_test = np.sum(weights_test)

t_value = (weighted_mean_control - weighted_mean_test) / np.sqrt(weighted_var_control/n_control + weighted_var_test/n_test)

```