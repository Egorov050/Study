Стратификация - это один из способов понижения `SE`.

Предположим , мы проводим аб тест на наших пользователях. Отметим, что у нас есть программа лояльности. И у нас есть информация, какие пользователи зарегистрированы в программе , а какие нет. 

**Ковариата** - метрика, которая коррелирует с целевой метрикой, может быть измерена до эксперимента (строго говоря, нет) и не зависит от других экспериментов. В нашем случае факт регистрации в программе лояльности до эксперимента будет ковариатой. То есть ковариарта - это то, по какому признаку идет стратификация. 

С помощью ковариат можно разделить популяцию на непересекающиеся подмножества, которые будут обладать уникальным набором значений ковариат. Такие подмножества будем называть **стратами**.

В нашем примере будет две страты:

- первая - кто не зарегистрирован в программе лояльности;
- вторая - кто зарегистрирован в программе лояльности.

Посмотрим на исторические данные пользователей этих страт по отдельности. Допустим, мы выяснили, следующую информацию:

- доли страт в популяции равны и составляют 50%;
- средняя выручка за неделю в первой страте равна 2000 рублей, во второй - 3000 рублей;
- стандартные отклонения выручки за неделю равны 625 рублей в обеих стратах. При таких значениях отклонений объединение данных обеих страт будет иметь отклонение около 800 рублей, как было изначально.

![[Pasted image 20240730210141.png]]

Получается, пользователи разных страт имеют разные распределения метрики.

К чему это может привести? Как мы знаем, когда мы рандомно разбиваем выборку, то может получиться так, что количество пользователей первой страты в контрольной группе может оказаться больше чем в экспериментальной, и наоборот. Это может привести к неверным результатам при оценке пилота, так как средние значения метрики в стратах отличаются.

Проведем эксперимент. 

Сгенерируем две страты поровну, как будто у нас 50% пользователей зарегистрировано , а другие 50% нет. Первая страта будет иметь одно распределение, вторая страта другое. Как только мы сгенерируем, объеденим их и проедем два АА теста. Первый, без разделения при формировании контрольной и тестовой выборки на страты, а второй с разделением. 

```python
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats

strata1c = np.random.normal(100, 50, 10000)
strata2c = np.random.normal(150, 45, 10000)
control = np.concatenate((strata1c, strata2c))

massive = []

for i in range(1000):
    group_1 = np.random.choice(control, 10000, replace = True)
    group_2 = np.random.choice(control, 10000, replace = True)

    _, p_value = stats.ttest_ind(group_1,group_2, alternative='two-sided')

    massive.append(p_value < 0.05)
    
np.mean(massive)

# результат : 

0.055
```

А теперь повторим только с делением : 

```python

massivve = []

for i in range(1000):
    group_1_1 = np.random.choice(strata1c, 5000, replace = True)
    group_1_2 = np.random.choice(strata2c, 5000, replace = True)
    control1 = np.concatenate((group_1_1, group_1_2))

    group_2_1 = np.random.choice(strata1c, 5000, replace = True)
    group_2_2 = np.random.choice(strata2c, 5000, replace = True)
    control2 = np.concatenate((group_2_1, group_2_2))

    _, p_value = stats.ttest_ind(control1,control2, alternative='two-sided')

    massivve.append(p_value < 0.05)

np.mean(massivve)

# результат : 

0.022
    
```

Мы видим, что ошибка первого рода сократилась примерно в два раза ( *PS она может сокращаться еще сильнее* )

Давайте сделаем точно также, только глянем на ошибку второго рода , и на 