`Мэтчинг (matching) в A/B тестах` — это метод статистической обработки данных, который используется для уменьшения смещения и обеспечения большей сопоставимости между контрольной и экспериментальной группами. Основная цель мэтчинга — создать пары или группы участников, которые похожи по ключевым характеристикам, чтобы можно было более точно оценить влияние тестируемого изменения.

Так нам интересно посчитать `ATE` , а это $E(y_i(1) - y_i(0))$ , но мы уже говорили, что мы не можем такое посчитать. То в таком случае, идея заключается в том, чтобы считать разницу для $E(y_i(1) - y_i(0))$ у близких по иксу наблюдений. 

Например : 

| y_i | d_i | x_i | user_id |
| --- | --- | --- | ------- |
| 6   | 1   | 21  | 0       |
| 7   | 0   | 40  | 1       |
| 8   | 1   | 70  | 2       |
| 10  | 1   | 45  | 3       |
| 1   | 0   | 15  | 4       |
| 3   | 0   | 79  | 5       |

В этой таблице у нас y_i это значение нашей метрики, d_i это в какую группу попал человек, а x_i это какая - то характеристика нашего пользователя ( например возраст )

В таком случае, например для `user_id == 0`, лучший мэтч это `user_id == 4` так как это ближайший человек по возрасту. Для `user_id == 2` мэтч с `user_id == 5` и для `user_id == 1` мэтч с `user_id == 3` . 

И дальше мы уже считаем разницу : 
(6 - 1) + (8 - 3) + (10 - 7) / 3 - и это и будет наш `ATE`

Мы можем брать не только одного ближайшего соседа, но и несколько. Тут работает принцип KNN. 

Но тут вопрос как понять, что отличие значимо от нуля? 

Очевидно, что нам нужен `c.i и se`
То есть `( ATE_left_match ; ATE_right_match )` и если в нашем интервале содержится нуль, то в таком случае отличий нет. 

Но теории, как получить `se` нет, поэтому тут мы должны использовать бутстрап. 
По идее, `ATE_match` будет стремиться к обычному `ATE`. Но эта сходимость тем медленее, чем больше предикторов в KNN ( то есть наших $x_i$). (*PS когда мы делаем KNN, не забываем масштабировать признаки.*) Дак вот, мы делаем метчинг и если у нас предикторов очень много, то все развалится. 

И вот тут как раз нужен `PS - Propencity score`. Она представляет собой вероятность того, что объект (например, человек или единица анализа) попадет в экспериментальную группу, учитывая его наблюдаемые характеристики.







