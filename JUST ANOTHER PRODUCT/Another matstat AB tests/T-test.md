По классике, мы используем `t-test` когда мы не знаем `population std` или когда мы знаем `population std` но при этом у нас количество наблюдений в семпле `меньше 30`

Для начала вспомним теорию по `t-test`

$$
t = \frac{\overline{X} - \mu}{\frac{s}{\sqrt{n}}}
$$
Это Формула `t-теста` для проверки разницы между средним значением выборки и гипотетическим средним значением (μ). Здесь мы знаем наше среднее выборки (${\overline{X}}$) а также дисперсию нашей выборки. 

Значение `t-value` в контексте `t-теста` показывает, насколько среднее значение выборки отличается от гипотетического среднего значения или среднего значения другой выборки в единицах стандартной ошибки. 

${\frac{s}{\sqrt{n}}}$   :   это стандартная ошибка среднего. Оно показывает, насколько среднее значение выборки (выборочное среднее) может варьироваться от истинного среднего значения генеральной совокупности, если бы вы взяли множество выборок из этой генеральной совокупности.

Представим , что мы выдвигаем гипотезы : 

H0​ : μ = ${\overline{X}}$

H1 :  μ > ${\overline{X}}$

Мы высчитываем нашу `t-статистику` и сравниваем с `t-value`. Если тот разброс, который мы получили ( `t - стистика` ) меньше чем `t-value` , то тогда у нас подтверждается нулевая гипотеза. Если же `t-статитистика` больше чем `t-value` => тогда мы отклоняем нулевую гипотезу в пользу альтернативной. 

По сути, если мы посмотрим на следующие формулы : 


$$
\text{Left} = \overline{X} - t_{\alpha/2, \, df} \cdot \frac{s}{\sqrt{n}} 
$$

$$
\text{Right} = \overline{X} + t_{\alpha/2, \, df} \cdot \frac{s}{\sqrt{n}} 
$$

То мы можем им объяснить следующим образом. ${\frac{s}{\sqrt{n}}}$  это своего образа единица / мера ,  которую мы умножаем на то количество  $\sigma$  , чтобы определить диапазон отрезка, в котором с определенной вероятностью будет находится среднее ген.совокупности. 

![[Screenshot 2024-07-20 at 15.36.04.png]]

Затем мы прибавляем у убавляем эти значения от нашего среднего выборки и получаем наш доверительный интервал. Если у нас двухсторонний тест, то есть мы имеем двухстороннюю гипотезу : 

H0​ : μ = ${\overline{X}}$

H1 :  μ != ${\overline{X}}$

то в таком случае, мы можем проверить гипотезу так : 

Мы строим доверительный интервал относительно нашего гепотетического сренего популяции ( μ ) : 

$$
\text{Left} = μ  - t_{\alpha/2, \, df} \cdot \frac{s}{\sqrt{n}} 
$$
$$
\text{Right} = μ  + t_{\alpha/2, \, df} \cdot \frac{s}{\sqrt{n}} 
$$
И если наше среднее выборки ( ${\overline{X}}$ ) > Right or ( ${\overline{X}}$ ) < Left, в таком случае мы отвергаем нулевую гипотезу в пользу альтернативной. 

<h6>Как сделать это на питоне</h6>
Для начала сгенерируем данные : 

```python 
data = np.random.normal(loc=5, scale=1, size=300000) 

# среднее 5 и дисперсия 1
```

Далее : 

```python 
m = np.array(data).mean()
s = np.array(data).std()

# мы предполагаем, что среднее ген.совокупости равно 5.0001 : 
mu = 5.0001

# считаем t статистику : 
sem = s / np.sqrt(300000)
(m - mu)/sem
```

Мы получаем, что `t-статистика` равна 1.0871325864340815. Это значит, что мы не отрицаем нулевую гипотезу. 

Перейдем к случаю, когда мы хотим протестировать гипотезу о разности двух средних выборок. Есть два варианта в исполнении т-теста, как это можно сделать. Используя пуловую дисперсию или через тест Уелча [[Welch's T-test]]. Здесь мы рассмотрим обычный тест с пуловой дисперсией. 

<h6>T-test diff of sample means </h6>
Так как мы используем пуловую дисперсию, которая считается следующим способом : 

$$
S_p^2 = \frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}
$$
мы должны в первую очередь сказать, что мы верим в равность наших population var. 

Итак, для подсчета `t-value` мы воспользуемся следующей формулой : 
$$
t = \frac{\bar{X}_1 - \bar{X}_2}{S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
$$
Далее уже по классике. В случае одностороннего теста , мы сравниваем `t - статистику` с `t - value` и уже на основе этого делаем вывод. 

Если речь идет про двухсторонний тест , то мы можем сравнивать следующим образом : 
$$
Border  =   t_{\alpha/2, \, df} \cdot \sqrt{S_p^2 \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}
$$
Если ${\bar{X}_1 - \bar{X}_2}$ > Border, то в таком случае мы отклоняем нулевую гипотезу в пользу альтернативной. 

<h6>На питоне</h6>
Сейчас разберемся, как 
