 Итак, очевидно что размер выборки , напрямую зависит , от дисперсии, ошибок первого и второго рода. 

Размер выборки мы можем посчитать по следующей формуле : 

$$
n > \left\lceil \left( Z_{\alpha/2} + Z_{\beta} \right)^2 \cdot \frac{(\sigma^2_x + \sigma^2_y)}{\Delta^2} \right\rceil
$$

Очевидно, чем `больше MDE` мы хотим видеть ($\Delta$) , тем меньше наблюдений мы должны собрать и наооборот. Чем `меньше` мы хотим обнаружить разницу , тем `больше` мы должны собрать наблюдений.  

Данная формула применяется для расчета `общего необходимого размера выборки`, то есть `суммарного` количества наблюдений, необходимых для обоих групп — контрольной и тестовой. Таким образом, `n` в этой формуле учитывает как контрольную, так и тестовую выборку вместе.

Также из формулы выше мы можем вывести формулу для подсчета `MDE`, который мы можем получить : 

$$
\Delta > \sqrt{\frac{\left( Z_{\alpha/2} + Z_{\beta} \right)^2 \cdot (\sigma^2_x + \sigma^2_y)}{n}}
$$

Допустим, при наших обстоятельствах, `MDE` равен 100 , а эксперимент может принести максимум `+10` к метрике. В таком случае , мы не сможем обнаружить этот эффект и нам лучше будет отказаться от такого эксперимента. 

Но тут не забываем про `Average Treatment Effect` , то есть про реальный эффект, который мы получили при АБ тесте. Тут у нас появляется три варианта развития событий : 

1.  Если реальный эффект `равен`  MDE  , то ошибка второго рода такая же, как и была в дизайне эксперимента. 
2. Если реальный эффект `больше` чем MDE  , то ошибка второго рода меньше , чем была в дизайне эксперимента. Это означает , что мы обнаружим эффект. 
3. Если реальный эффект `меньше` чем MDE , то ошибка второго рода больше , чем было заявлено в дизайне эксперимента. Это означает , что скорее всего мы `не обнаружим` эффект. 

Также , исходя из тех данных, которые представлены выше, мы можем составить матрицу того , как ошибка первого , второго рода , а также `MDE` будет влиять на выборку. Сделаем такую матрицу : 

```python

alphas = [0.5, 0.2, 0.1, 0.05, 0.01]
betas = [0.5, 0.2, 0.1, 0.05, 0.01]
MDE = 3

result = []

stdControl = 24
stdTets = 23

for a in alphas:
    for b in betas:
        t_alpha = stats.norm.ppf(1 - a / 2)  
        t_betta = stats.norm.ppf(1 - b / 2)  
        n = (t_alpha + t_betta) ** 2 * (stdControl**2 + stdTets**2) / MDE**2

        result.append({
            'alpha' : a, 
            'beta' : b,
            'n' : n})

df = pd.DataFrame(result)
df['n'] = df['n'].astype(int)
pd.pivot_table(data=df, index='alpha', columns='beta', values='n')

```


И получаем следующий результат : 






