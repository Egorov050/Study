Когда речь идет про `ratio - метрики` , то здесь не все так просто. Проблема заключается в том, что знаменатель и числитель связаны друг с другом, `из - за этого обычный t - test не справится так как мы не правильно там считаем дисперсию!` Поэтому есть несколько способ, как избежать ошибку в подсчете дисперсии. Один из них это `дельта - метод.`

Для начально вспомним, что формально метрики отношений можно представлять так : 

$$
	R = \frac{X_1 ....X_n}{Y_1 .... Y_n}
$$

`Дельта-метод` — это метод в математической статистике, используемый для приближённого вычисления распределения функции от случайной величины. Этот метод часто применяется для получения приближений распределений функций от случайных величин, когда точные распределения трудно найти или не известны.

Есть `одномерный и двухмерный` дельта - метод.

<h6>Одномерный дельта - метод</h6>

Одномерный дельта-метод — это метод приближения распределения функции от случайной величины, используя её первое и второе производные. Он часто применяется для нахождения приближённого распределения функции случайной величины, когда функция сложная, а распределение её точное найти сложно.

В общем виде это выглядит так : 

Пусть $( X_n )$ — последовательность случайных величин, таких что:

$$
\sqrt{n}(X_n - \theta) \xrightarrow{d} N(0, \sigma^2)
$$

при $( n \to \infty$\), где $\theta$ — некоторое значение параметра, $N(0, \sigma^2)$  — нормальное распределение с математическим ожиданием 0 и дисперсией $\sigma^2$.

Если \( g \) — функция, которая имеет непрерывную производную в точке $(\theta)$, то:

$$
Среднее:   \mathbb{E}[g(X_n)] \approx g(\theta) 
$$

$$
Дисперсия: \text{Var}[g(X_n)] \approx{\sigma^2 [g'(\theta)]^2}
$$

Рассмотрим простой пример `одномерного дельта-метода`.

Пусть X  — случайная величина, имеющая распределение $N(\mu, \sigma^2)$, то есть нормальное распределение с математическим ожиданием $mu$ и дисперсией $sigma^2$. Мы хотим найти приближенное распределение функции $Y = g(X)$, где функция  $g$ задана как $g(x) = \sqrt{x}$

Решение:

1 Найдём первую и вторую производные функции $g(x)$.
Функция $g(x) = \sqrt{x}$. Найдём её производную:
Первая производная: $g'(x) = \frac{1}{2\sqrt{x}}$.

2 Рассчитаем приближенную дисперсию \( Y \) с помощью дельта-метода.

По дельта-методу, если ( X ) имеет нормальное распределение $N(\mu, \sigma^2)$ и функция $g(x)$ дифференцируема, то приближённое распределение функции $g(X)$ можно найти следующим образом:

Приближённое математическое ожидание ( Y ):

$$
\mathbb{E}[Y] \approx g(\mu) = \sqrt{\mu}
$$

Приближённая дисперсия \( Y \):

$$
\text{Var}(Y) \approx \left(g'(\mu)\right)^2 \text{Var}(X) = \left(\frac{1}{2\sqrt{\mu}}\right)^2 \sigma^2 = \frac{\sigma^2}{4\mu}
$$



<h6>Двухмерный дельта - метод</h6>

Теперь перейдем к `двухмерному дельта - методу КОНКРЕТНО ДЛЯ RATIO - МЕТРИКИ.` Именно его мы и будем использовать при подсчете доверительного интервала для ratio - метрики.

Приближенную оценку дисперсии отношения двух случайных величин Y и X имеет следующий общий вид : 

$$
\text{Var}\left(\frac{Y}{X}\right) \approx(\frac{\mathbb{E}(Y)^2}{\mathbb{E}(X)^4} \text{Var}(X) + \frac{\mathbb{E}(Y)^4}{\mathbb{E}(X)^2} \text{Var}(Y) - 2 \frac{\mathbb{E}(Y)^3}{\mathbb{E}(X)^3} \text{Cov}(X, Y))
$$

Таким образом , мы можем посчитать : 

$$
	R_{control} = \frac{X_1 ....X_n}{Y_1 .... Y_n}
$$

$$
	R_{test} = \frac{X_1 ....X_n}{Y_1 .... Y_n}
$$

Посчитать дисперсию для тестовой и контрольной выборки : 

$$
\text{Var}\left(\frac{Y}{X}\right) \approx (\frac{1}{n})(\frac{\mathbb{E}(Y)^2}{\mathbb{E}(X)^4} \text{Var}(X) + \frac{\mathbb{E}(Y)^4}{\mathbb{E}(X)^2} \text{Var}(Y) - 2 \frac{\mathbb{E}(Y)^3}{\mathbb{E}(X)^3} \text{Cov}(X, Y))
$$

и затем просто посчитать t - value : 

$$
t_{value} = \frac{R_b - R_a}{\sqrt{V(R_a) + V(R))}}
$$

Давайте смоделируем это все на питоне : 

```python

import numpy as np
from scipy import stats

# Исходные данные
data_a = np.array([
    [1, 0, 1, 0, 1],  # примеры данных для кампании A
    [1, 1, 0, 1, 1],
    [0, 1, 1, 0, 0],
    [1, 0, 1, 1, 1],
    [0, 0, 0, 0, 0]
])
data_b = np.array([
    [1, 0, 0, 1, 0],  # примеры данных для кампании B
    [1, 1, 1, 1, 0],
    [0, 1, 1, 1, 1],
    [1, 0, 1, 0, 1],
    [0, 1, 0, 1, 0]
])


# Функция для расчета CTR и дисперсии
def calculate_ctr_and_variance(data):
    n_user = len(data)
    array_x = np.array([np.sum(row) for row in data])
    array_y = np.array([len(row) for row in data])
    
    mean_x = np.mean(array_x)
    mean_y = np.mean(array_y)
    var_x = np.var(array_x)
    var_y = np.var(array_y)
    cov_xy = np.cov(array_x, array_y)[0, 1]
    
    # Точечная оценка метрики
    pe_metric = np.sum(array_x) / np.sum(array_y)
    
    # Оценка дисперсии метрики
    var_metric = (
        var_x / mean_y ** 2
        - 2 * (mean_x / mean_y ** 3) * cov_xy
        + (mean_x ** 2 / mean_y ** 4) * var_y
    ) / n_user
    
    return pe_metric, var_metric


# Расчет для обеих кампаний
pe_metric_a, var_metric_a = calculate_ctr_and_variance(data_a)
pe_metric_b, var_metric_b = calculate_ctr_and_variance(data_b)


# Расчет t-статистики и p-значения
delta = pe_metric_b - pe_metric_a
var_diff = var_metric_a + var_metric_b
t_value = delta / np.sqrt(var_diff)
p_value = (1 - stats.norm.cdf(np.abs(t_value))) * 2


# Вывод результатов
print(f"CTR для кампании A: {pe_metric_a:.4f}")
print(f"Дисперсия метрики для кампании A: {var_metric_a:.4f}")
print(f"CTR для кампании B: {pe_metric_b:.4f}")
print(f"Дисперсия метрики для кампании B: {var_metric_b:.4f}")
print(f"Разность CTR (delta): {delta:.4f}")
print(f"t-value: {t_value:.4f}")
print(f"p-value: {p_value:.4f}")


# Построение доверительного интервала
z_value = 1.96  # для 95% доверительного интервала
ci_low = delta - z_value * np.sqrt(var_diff)
ci_high = delta + z_value * np.sqrt(var_diff)

print(f"95% доверительный интервал разности CTR: ({ci_low:.4f}, {ci_high:.4f})")



CTR для кампании A: 0.5200
Дисперсия метрики для кампании A: 0.0179
CTR для кампании B: 0.6000
Дисперсия метрики для кампании B: 0.0064
Разность CTR (delta): 0.0800
t-value: 0.5130
p-value: 0.6080
95% доверительный интервал разности CTR: (-0.2257, 0.3857)

```

По t-value и по p-value и по доверительному интервалу мы видим, что статистической разницы нет.