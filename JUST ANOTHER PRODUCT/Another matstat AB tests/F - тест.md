### Математические Формулы F-теста

F-тест используется для сравнения дисперсий двух выборок и проверки гипотезы о равенстве этих дисперсий. Вот основные математические формулы:

1. **Выборочная дисперсия для группы \(A\) и группы \(B\)**:

$$
   S_A^2 = \frac{1}{n_A - 1} \sum_{i=1}^{n_A} (X_i - \bar{X}_A)^2
$$

   $$
   S_B^2 = \frac{1}{n_B - 1} \sum_{i=1}^{n_B} (X_i - \bar{X}_B)^2
$$

   где $(n_A)$ и $(n_B)$ — размеры выборок, $(X_i)$ — элементы выборок, $(\bar{X}_A$) и $(\bar{X}_B\) — средние значения выборок.

2. **Статистика F**:

   \[
   F = \frac{S_A^2}{S_B^2}
   \]

   где \(S_A^2\) и \(S_B^2\) — выборочные дисперсии.

3. **Степени свободы**:

   \[
   \text{df}_1 = n_A - 1
   \]

   \[
   \text{df}_2 = n_B - 1
   \]

4. **p-значение**:

   \[
   p = P(F_{\text{df}_1, \text{df}_2} > F)
   \]

   где \(F_{\text{df}_1, \text{df}_2}\) — распределение F со степенями свободы \(\text{df}_1\) и \(\text{df}_2\).

### Принцип F-теста

F-тест основывается на сравнении двух дисперсий, чтобы определить, являются ли они статистически равными. Вот основные шаги выполнения F-теста:

1. **Формулировка гипотез**:
   - **Нулевая гипотеза (\(H_0\))**: Дисперсии двух выборок равны (\(\sigma_A^2 = \sigma_B^2\)).
   - **Альтернативная гипотеза (\(H_1\))**: Дисперсии двух выборок не равны (\(\sigma_A^2 \neq \sigma_B^2\)).

2. **Рассчитываем выборочные дисперсии**:
   - Вычисляем выборочные дисперсии для каждой выборки (\(S_A^2\) и \(S_B^2\)).

3. **Рассчитываем статистику F**:
   - Находим отношение выборочных дисперсий (\(F = \frac{S_A^2}{S_B^2}\)).

4. **Определяем критическое значение и p-значение**:
   - Сравниваем статистику F с критическим значением из распределения F с соответствующими степенями свободы, чтобы найти p-значение.

5. **Принимаем или отвергаем нулевую гипотезу**:
   - Если p-значение меньше уровня значимости (\(\alpha\)), отвергаем нулевую гипотезу и делаем вывод, что дисперсии значимо различаются. В противном случае, не отвергаем нулевую гипотезу.

### Пример кода на Python

```python
import numpy as np
from scipy import stats

# Пример данных
np.random.seed(42)
group_A = np.random.normal(100, 15, 100)  # контрольная группа
group_B = np.random.normal(105, 20, 100)  # тестовая группа

# Вычисление выборочных дисперсий
var_A = np.var(group_A, ddof=1)
var_B = np.var(group_B, ddof=1)

# Вычисление значения F
F = var_A / var_B

# Степени свободы
dfn = len(group_A) - 1
dfd = len(group_B) - 1

# Вычисление p-значения
p_value = stats.f.cdf(F, dfn, dfd)

# Так как F распределение симметричное, то p-value корректируем для двустороннего теста
if F > 1:
    p_value = 2 * (1 - p_value)
else:
    p_value = 2 * p_value

print(f"F-статистика: {F:.4f}")
print(f"p-значение: {p_value:.4f}")

# Проверка на равенство дисперсий
alpha = 0.05
if p_value < alpha:
    print("Дисперсии значимо различаются.")
else:
    print("Нет значимого различия в дисперсиях.")
```

### Интерпретация результатов:

- **F-статистика**: Отношение дисперсий двух выборок.
- **p-значение**: Вероятность наблюдения такого или более экстремального значения F при условии, что нулевая гипотеза (равенство дисперсий) верна.
- **Вывод**: Если p-значение меньше уровня значимости (например, 0.05), то гипотеза о равенстве дисперсий отвергается, и можно сделать вывод о значимом различии дисперсий. В противном случае, дисперсии считаются равными.