Для того, чтобы наша модель выдавала хорошие результаты, нам нужно подобрать оптимальные гиперпараметры. 

Существует несколько способов, как подобрать гиперпараметры. 
Одними из таких являются `GridSearchCV` , `RandomSearch`. 

<h6>GridSearchCV</h6>
`GridSearchCV` из библиотеки `scikit-learn` — это мощный инструмент для автоматического подбора гиперпараметров модели машинного обучения. Он позволяет систематически проверять набор параметров модели, чтобы найти наилучшие гиперпараметры, которые обеспечивают наилучшую производительность модели на основе кросс-валидации.

Рассмотрим на подборе параметров для `xgb`

Для начала импортируем `GridSearchCV` : 

```python 
from sklearn.model_selection import GridSearchCV
```

Затем, зададим параметры , из которых нам нужно выбрать один сет гиперпараметров : 

```python
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2]
}

```

Далее, инициализируем модель и приступим к тренировке : 

```python 
# Инициализация модели 
model = xgb.XGBClassifier() 

# Настройка поиска по сетке с кросс-валидацией 
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1) grid_search.fit(X_train, y_train)
```

И далее выведем лучшие параметры : 

```python
print("Лучшие параметры:", grid_search.best_params_)
print("Лучший результат на обучающем наборе:", grid_search.best_score_)
```

И далее, уже данные параметры используем для нашей модели. 

<h6>RandomSearch</h6>

`Random search (случайный поиск)` — это метод гиперпараметрической оптимизации, при котором гиперпараметры модели выбираются случайным образом из заданного диапазона значений. Вместо проверки всех возможных комбинаций, как это делается в grid search, random search выбирает случайные комбинации, что позволяет сэкономить время и вычислительные ресурсы.

<h6>Шаги работы random search :</h6>

`Определение пространства гиперпараметров` : Задаются диапазоны или распределения, из которых будут случайно выбраны значения гиперпараметров. Например, количество деревьев в лесу (n_estimators) может варьироваться от 10 до 200, а максимальная глубина дерева (max_depth) — от 1 до 20.

`Случайный выбор комбинаций гиперпараметров` :  Из заданных диапазонов случайным образом выбираются значения гиперпараметров. Эти значения используются для настройки модели.

`Оценка модели` : Для каждой выбранной случайной комбинации гиперпараметров модель обучается на обучающей выборке и оценивается с использованием метода кросс-валидации или на валидационной выборке.

`Повторение процесса `: Процесс случайного выбора и оценки гиперпараметров повторяется заданное количество раз (например, 100 итераций). Каждая итерация использует новую случайную комбинацию гиперпараметров.

`Выбор наилучшей комбинации` :  По окончании всех итераций выбирается та комбинация гиперпараметров, которая показала наилучшие результаты на валидационной выборке.

Пример : 

```python 

model = RandomForestClassifier() # Определяем пространство гиперпараметров для поиска 
param_dist = { 'n_estimators': randint(10, 200), 'max_depth': randint(1, 20) } # Инициализируем 

RandomizedSearchCV random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=100, cv=5, random_state=42, n_jobs=-1) 
# Обучаем модели и ищем наилучшие гиперпараметры 

random_search.fit(X_train, y_train) 

# Выводим наилучшие гиперпараметры и точность на тестовой выборке 
print("Лучшие гиперпараметры:", random_search.best_params_) 
print("Точность на тестовой выборке:", random_search.score(X_test, y_test))
```

 <h6>Когда выбирать Grid Search :</h6>

`Малое пространство гиперпараметров :` Если количество гиперпараметров и их возможных значений относительно невелико, grid search может быть хорошим выбором. Например, если у вас всего 2-3 гиперпараметра с небольшим количеством возможных значений, grid search позволит исчерпывающе проверить все комбинации.

`Необходимость исчерпывающего поиска :` Когда требуется гарантировать нахождение оптимальных значений гиперпараметров. Grid search проверяет все возможные комбинации, что позволяет найти глобальный оптимум.

`Достаточные вычислительные ресурсы :` Если у вас есть мощные вычислительные ресурсы и достаточно времени для выполнения поиска. Grid search может быть очень затратным по времени и ресурсам, особенно при увеличении числа гиперпараметров.

<h6>Когда выбирать Random Search :</h6>

`Большое пространство гиперпараметров :` Если у вас много гиперпараметров и большое количество возможных значений для каждого из них. В таких случаях grid search становится неэффективным, так как количество возможных комбинаций быстро растет.

`Ограниченные вычислительные ресурсы :`  Когда вычислительные ресурсы и время ограничены. Random search позволяет выполнить меньшее количество проверок, охватывая при этом большое пространство гиперпараметров.

`Необходимость быстрого поиска :` Если вам нужно быстро получить хорошие результаты, а не обязательно найти абсолютный оптимум. Random search часто находит достаточно хорошие комбинации гиперпараметров за меньшее время.

`Высокая вероятность нахождения хороших гиперпараметров :` Когда диапазон возможных значений гиперпараметров большой, random search имеет более высокую вероятность найти хорошие комбинации, поскольку случайные выборки охватывают большее пространство.
