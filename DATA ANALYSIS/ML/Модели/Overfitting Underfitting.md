<h6>Переобучение линейных моделей</h6>

Для начала рассмотрим переобучение на примере `линейных моделей`. 
Если у нас модель `переобучена`, то в таком случае , у нас алгоритм будет близко предугадывать значения на тестовой выборке. То есть если мы будем смотреть по MSE, то оно будет близко к нулю. 

Однако , если мы посмотрим на `MSE` уже когда мы сравниваем наш предикт по X_test с y_test , то в таком случае, у нас `MSE` будет велико.

То есть в случае переобучения, наша модель не запоминает то, что происходит в задаче в целом. Она запоминает только то, что происходила в обучающей выборке. Из-за этого у нас такие хорошие показатели на обучающей выборке и такие плохие показатели на тренировочной. 

![[Screenshot 2024-07-14 at 17.40.22.png]]

Поэтому нужно обязательно проверять модель на переобучение. 

<h6>Переобучение нелинейных моделей</h6>

Теперь поговорим про такие модели как `Random forest` и `градиентный бустинг`.



