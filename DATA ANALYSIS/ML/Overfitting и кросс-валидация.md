<h6>Переобучение линейных моделей</h6>

Для начала рассмотрим переобучение на примере `линейных моделей`. 
Если у нас модель `переобучена`, то в таком случае , у нас алгоритм будет близко предугадывать значения на тестовой выборке. То есть если мы будем смотреть по MSE, то оно будет близко к нулю. 

Однако , если мы посмотрим на `MSE` уже когда мы сравниваем наш предикт по X_test с y_test , то в таком случае, у нас `MSE` будет велико.

То есть в случае переобучения, наша модель не запоминает то, что происходит в задаче в целом. Она запоминает только то, что происходила в обучающей выборке. Из-за этого у нас такие хорошие показатели на обучающей выборке и такие плохие показатели на тренировочной. 

![[Screenshot 2024-07-14 at 17.40.22.png]]

Поэтому нужно обязательно проверять модель на переобучение. 

<h6>Переобучение нелинейных моделей</h6>

Теперь поговорим про такие модели как `Random forest` и `градиентный бустинг`.

Для начала вспомним что такое `bias` и `variance` 

![[Screenshot 2024-07-14 at 18.06.53.png]]

`Смещение (bias)`— это ошибка модели, возникающая из-за чрезмерного упрощения алгоритма. Высокое смещение приводит к тому, что модель недостаточно хорошо учитывает данные, что ведет к недообучению. Это значит, что модель не улавливает основные зависимости в данных.

`Дисперсия (variance)` — это ошибка модели, возникающая из-за высокой чувствительности к изменениям в обучающих данных. Высокая дисперсия означает, что модель слишком сильно подстраивается под обучающие данные, что ведет к переобучению. Это значит, что модель хорошо работает на обучающих данных, но плохо обобщает на новых данных.

![[Screenshot 2024-07-14 at 18.12.41.png]]

При переобучении : 

- `Смещение (bias)` : низкое. Модель слишком точно подгоняется под обучающие данные, включая шум и случайные колебания. Это приводит к тому, что смещение становится низким, так как модель хорошо описывает обучающие данные.
- `Дисперсия (variance)` : высокое. Модель становится очень чувствительной к изменению данных. Это значит, что небольшие изменения в данных могут существенно изменить предсказания модели, что ведет к плохой обобщаемости на новых, тестовых данных.

Для того, чтобы понимать , как наши модели будут вести себя в жизни, мы должны применить такую методику как `кросс - валидация`. 

`Кросс-валидация` — это метод оценки производительности модели машинного обучения, который позволяет более точно определить, как модель будет работать на новых, ранее не виденных данных. Этот метод помогает в оценке обобщающей способности модели и в уменьшении переобучения. 

Основная идея кросс-валидации заключается в разделении данных на несколько подмножеств и многократной оценке модели на различных частях данных.

Для того, чтобы провести кросс - валидацию,  импортируем ее : 

```python
from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer, mean_squared_error

```

Далее, по классике мы работаем с нашими данными , чистим их, нормализуем, делим на тестовый и тренировочные семплы. Когда дело подходит до тренировки модели , то : 

```python 
# сначала инициализиуруем модель : 
model = LinearRegression()


#далее мы инициализируем метрирку, по которой будем оценивать нашу модель : 
mse_scorer = make_scorer(mean_squared_error)


scores = cross_val_score(model, X, y, cv=10, scoring=mse_scorer)
```


Функция `make_scorer` из библиотеки `scikit-learn` в Python позволяет создать пользовательские метрики оценки для моделей машинного обучения. Это полезно, когда вы хотите использовать метрику, которая не включена в стандартный набор метрик, предоставляемых `scikit-learn`, или если вы хотите модифицировать стандартные метрики для своих нужд.
